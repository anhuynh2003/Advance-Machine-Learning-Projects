{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: “Lab 1”\n",
    "author: An Huynh\n",
    "format: \n",
    "    html:\n",
    "        toc: true\n",
    "        code-fold: true \n",
    "        code-summary: \"Show code\"\n",
    "embed-resources: true\n",
    "editor: visual\n",
    "theme: flatly \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:51: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/468405663.py:52: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = \"/Users/anhuynh/Downloads/archive (5)/\"\n",
    "\n",
    "file_month_map = {\n",
    "    \"November sleep data - Sheet1.csv\": \"November\",\n",
    "    \"December sleep data - Sheet1.csv\": \"December\",\n",
    "    \"January sleep data - Sheet1.csv\": \"January\",\n",
    "    \"February sleep data - Sheet1 (1).csv\": \"February\",\n",
    "    \"March sleep data - Sheet1.csv\": \"March\",\n",
    "    \"April sleep data - Sheet1.csv\": \"April\"\n",
    "}\n",
    "\n",
    "monthly_dfs = []\n",
    "\n",
    "# Process each file\n",
    "for filename, month in file_month_map.items():\n",
    "    file_path = os.path.join(base_path, filename)\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Rename inconsistent columns\n",
    "    df.rename(columns={df.columns[0]: \"Weekday\"}, inplace=True)\n",
    "    df.rename(columns={\n",
    "        \"SLEEP SQORE\": \"SLEEP SCORE\",\n",
    "        \"HEARTRATE BELOW RESTING\": \"HEART RATE BELOW RESTING\",\n",
    "        \"HEART RATE UNDER RESTING\": \"HEART RATE BELOW RESTING\"\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Add month column\n",
    "    df[\"Month\"] = month\n",
    "\n",
    "    # Convert 'DATE' to datetime and drop invalid ones\n",
    "    df[\"Date\"] = pd.to_datetime(df[\"DATE\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"Date\"])\n",
    "\n",
    "    # Extract actual weekday\n",
    "    df[\"Weekday\"] = df[\"Date\"].dt.day_name()\n",
    "\n",
    "    # Convert percentage columns to decimal\n",
    "    percent_cols_to_convert = [\"REM SLEEP\", \"DEEP SLEEP\", \"HEART RATE BELOW RESTING\"]\n",
    "    for col in percent_cols_to_convert:\n",
    "        df[col] = df[col].str.replace('%', '', regex=False).astype(float) / 100\n",
    "\n",
    "    # Split 'SLEEP TIME'\n",
    "    if \"SLEEP TIME\" in df.columns:\n",
    "        df[\"SLEEP START\"] = df[\"SLEEP TIME\"].str.split(\"-\").str[0].str.strip()\n",
    "        df[\"SLEEP END\"] = df[\"SLEEP TIME\"].str.split(\"-\").str[1].str.strip()\n",
    "\n",
    "    # Convert 'SLEEP START' and 'SLEEP END' to hour\n",
    "    df['SLEEP START'] = pd.to_datetime(df['SLEEP START'], errors='coerce').dt.hour\n",
    "    df['SLEEP END'] = pd.to_datetime(df['SLEEP END'], errors='coerce').dt.hour\n",
    "\n",
    "    # Keep only expected columns\n",
    "    expected_cols = [\n",
    "        \"Month\", \"Weekday\", \"Date\", \"SLEEP SCORE\", \"HOURS OF SLEEP\", \"REM SLEEP\",\n",
    "        \"DEEP SLEEP\", \"HEART RATE BELOW RESTING\", \"SLEEP TIME\", \"SLEEP START\", \"SLEEP END\"\n",
    "    ]\n",
    "    df = df[[col for col in expected_cols if col in df.columns]]\n",
    "\n",
    "    # Append the clean df\n",
    "    monthly_dfs.append(df)\n",
    "\n",
    "# Combine all months\n",
    "df = pd.concat(monthly_dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Month    Weekday       Date  SLEEP SCORE HOURS OF SLEEP  REM SLEEP  \\\n",
      "0  November     Monday 2021-11-01         88.0        8:06:00       0.20   \n",
      "1  November    Tuesday 2021-11-02         83.0        7:57:00       0.12   \n",
      "2  November  Wednesday 2021-11-03         81.0        7:06:00       0.13   \n",
      "3  November   Thursday 2021-11-04         86.0        7:04:00       0.19   \n",
      "4  November     Friday 2021-11-05         81.0        9:24:00       0.17   \n",
      "\n",
      "   DEEP SLEEP  HEART RATE BELOW RESTING        SLEEP TIME  SLEEP START  \\\n",
      "0        0.13                      0.84  10:41pm - 7:54am         22.0   \n",
      "1        0.18                      0.90  10:40pm - 7:55am         22.0   \n",
      "2        0.22                      0.93  11:03pm - 7:16am         23.0   \n",
      "3        0.17                      0.97  10:55pm - 6:56am         22.0   \n",
      "4        0.15                      0.66  10:14pm - 9:01am         22.0   \n",
      "\n",
      "   SLEEP END  \n",
      "0        7.0  \n",
      "1        7.0  \n",
      "2        7.0  \n",
      "3        6.0  \n",
      "4        9.0  \n"
     ]
    }
   ],
   "source": [
    "# Function to convert HH:MM or HH:MM:SS to total seconds\n",
    "def time_to_seconds(t):\n",
    "    try:\n",
    "        parts = t.split(\":\")\n",
    "        parts = list(map(int, parts))\n",
    "        if len(parts) == 2:  # HH:MM\n",
    "            h, m = parts\n",
    "            s = 0\n",
    "        elif len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "        else:\n",
    "            return np.nan\n",
    "        return h * 3600 + m * 60 + s\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "#print(df['Month'].unique())\n",
    "\n",
    "# Apply to your column\n",
    "df[\"SLEEP DURATION SECONDS\"] = df[\"HOURS OF SLEEP\"].apply(time_to_seconds)\n",
    "\n",
    "# Also useful to get decimal hours\n",
    "df[\"SLEEP DURATION HOURS\"] = df[\"SLEEP DURATION SECONDS\"] / 3600\n",
    "\n",
    "### Combine all of the months into a single DataFrame\n",
    "combined_data = pd.concat(monthly_dfs, ignore_index=True)\n",
    "\n",
    "### Data cleaning\n",
    "data = combined_data.dropna()\n",
    "\n",
    "# Display the cleaned data\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/3228070899.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"SLEEP DURATION SECONDS\"] = data[\"HOURS OF SLEEP\"].apply(time_to_seconds)\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/3228070899.py:21: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data[\"SLEEP DURATION HOURS\"] = data[\"SLEEP DURATION SECONDS\"] / 3600\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Function to convert HH:MM or HH:MM:SS to total seconds\n",
    "def time_to_seconds(t):\n",
    "    try:\n",
    "        parts = t.split(\":\")\n",
    "        parts = list(map(int, parts))\n",
    "        if len(parts) == 2:  # HH:MM\n",
    "            h, m = parts\n",
    "            s = 0\n",
    "        elif len(parts) == 3:  # HH:MM:SS\n",
    "            h, m, s = parts\n",
    "        else:\n",
    "            return np.nan\n",
    "        return h * 3600 + m * 60 + s\n",
    "    except:\n",
    "        return np.nan\n",
    "\n",
    "# Apply to your column\n",
    "data[\"SLEEP DURATION SECONDS\"] = data[\"HOURS OF SLEEP\"].apply(time_to_seconds)\n",
    "\n",
    "# Also useful to get decimal hours\n",
    "data[\"SLEEP DURATION HOURS\"] = data[\"SLEEP DURATION SECONDS\"] / 3600\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['PREV_SLEEP_START'] = data['SLEEP START'].shift(1)\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['PREV_SLEEP_START'] = data['SLEEP START'].shift(1).fillna(0)\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['SLEEP_START_VARIABILITY'] = (data['SLEEP START'] - data['PREV_SLEEP_START']).abs()\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['SLEEP_START_VARIABILITY']  = data['SLEEP_START_VARIABILITY'] .fillna(0)\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Is_Weekend'] = data['Weekday'].isin(['Saturday', 'Sunday']).astype(int)\n",
      "/var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/ipykernel_48638/318578420.py:22: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['Season'] = data['Month'].map(season_map)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Month</th>\n",
       "      <th>Weekday</th>\n",
       "      <th>Date</th>\n",
       "      <th>SLEEP SCORE</th>\n",
       "      <th>HOURS OF SLEEP</th>\n",
       "      <th>REM SLEEP</th>\n",
       "      <th>DEEP SLEEP</th>\n",
       "      <th>HEART RATE BELOW RESTING</th>\n",
       "      <th>SLEEP TIME</th>\n",
       "      <th>SLEEP START</th>\n",
       "      <th>SLEEP END</th>\n",
       "      <th>SLEEP DURATION SECONDS</th>\n",
       "      <th>SLEEP DURATION HOURS</th>\n",
       "      <th>PREV_SLEEP_START</th>\n",
       "      <th>SLEEP_START_VARIABILITY</th>\n",
       "      <th>Is_Weekend</th>\n",
       "      <th>Season</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>November</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2021-11-01</td>\n",
       "      <td>88.0</td>\n",
       "      <td>8:06:00</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.84</td>\n",
       "      <td>10:41pm - 7:54am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>29160</td>\n",
       "      <td>8.100000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>November</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2021-11-02</td>\n",
       "      <td>83.0</td>\n",
       "      <td>7:57:00</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10:40pm - 7:55am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>28620</td>\n",
       "      <td>7.950000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>November</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2021-11-03</td>\n",
       "      <td>81.0</td>\n",
       "      <td>7:06:00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.93</td>\n",
       "      <td>11:03pm - 7:16am</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25560</td>\n",
       "      <td>7.100000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>November</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2021-11-04</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7:04:00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.97</td>\n",
       "      <td>10:55pm - 6:56am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>25440</td>\n",
       "      <td>7.066667</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>November</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2021-11-05</td>\n",
       "      <td>81.0</td>\n",
       "      <td>9:24:00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.66</td>\n",
       "      <td>10:14pm - 9:01am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>33840</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Fall</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>April</td>\n",
       "      <td>Tuesday</td>\n",
       "      <td>2022-04-26</td>\n",
       "      <td>85.0</td>\n",
       "      <td>7:18:00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1.00</td>\n",
       "      <td>9:32pm - 6:00am</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>26280</td>\n",
       "      <td>7.300000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>April</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2022-04-27</td>\n",
       "      <td>90.0</td>\n",
       "      <td>7:34:00</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.98</td>\n",
       "      <td>9:19pm - 5:49am</td>\n",
       "      <td>21.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27240</td>\n",
       "      <td>7.566667</td>\n",
       "      <td>21.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>April</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2022-04-28</td>\n",
       "      <td>87.0</td>\n",
       "      <td>6:54:00</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.90</td>\n",
       "      <td>10:02pm - 5:46am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>24840</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>April</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2022-04-29</td>\n",
       "      <td>86.0</td>\n",
       "      <td>7:45:00</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.95</td>\n",
       "      <td>10:15pm - 7:24am</td>\n",
       "      <td>22.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>27900</td>\n",
       "      <td>7.750000</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>April</td>\n",
       "      <td>Saturday</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>89.0</td>\n",
       "      <td>7:11:00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11:08pm - 7:04am</td>\n",
       "      <td>23.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>25860</td>\n",
       "      <td>7.183333</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>Spring</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Month    Weekday       Date  SLEEP SCORE HOURS OF SLEEP  REM SLEEP  \\\n",
       "0    November     Monday 2021-11-01         88.0        8:06:00       0.20   \n",
       "1    November    Tuesday 2021-11-02         83.0        7:57:00       0.12   \n",
       "2    November  Wednesday 2021-11-03         81.0        7:06:00       0.13   \n",
       "3    November   Thursday 2021-11-04         86.0        7:04:00       0.19   \n",
       "4    November     Friday 2021-11-05         81.0        9:24:00       0.17   \n",
       "..        ...        ...        ...          ...            ...        ...   \n",
       "176     April    Tuesday 2022-04-26         85.0        7:18:00       0.22   \n",
       "177     April  Wednesday 2022-04-27         90.0        7:34:00       0.24   \n",
       "178     April   Thursday 2022-04-28         87.0        6:54:00       0.21   \n",
       "179     April     Friday 2022-04-29         86.0        7:45:00       0.19   \n",
       "180     April   Saturday 2022-04-30         89.0        7:11:00       0.22   \n",
       "\n",
       "     DEEP SLEEP  HEART RATE BELOW RESTING        SLEEP TIME  SLEEP START  \\\n",
       "0          0.13                      0.84  10:41pm - 7:54am         22.0   \n",
       "1          0.18                      0.90  10:40pm - 7:55am         22.0   \n",
       "2          0.22                      0.93  11:03pm - 7:16am         23.0   \n",
       "3          0.17                      0.97  10:55pm - 6:56am         22.0   \n",
       "4          0.15                      0.66  10:14pm - 9:01am         22.0   \n",
       "..          ...                       ...               ...          ...   \n",
       "176        0.14                      1.00   9:32pm - 6:00am         21.0   \n",
       "177        0.19                      0.98   9:19pm - 5:49am         21.0   \n",
       "178        0.22                      0.90  10:02pm - 5:46am         22.0   \n",
       "179        0.17                      0.95  10:15pm - 7:24am         22.0   \n",
       "180        0.18                      0.75  11:08pm - 7:04am         23.0   \n",
       "\n",
       "     SLEEP END  SLEEP DURATION SECONDS  SLEEP DURATION HOURS  \\\n",
       "0          7.0                   29160              8.100000   \n",
       "1          7.0                   28620              7.950000   \n",
       "2          7.0                   25560              7.100000   \n",
       "3          6.0                   25440              7.066667   \n",
       "4          9.0                   33840              9.400000   \n",
       "..         ...                     ...                   ...   \n",
       "176        6.0                   26280              7.300000   \n",
       "177        5.0                   27240              7.566667   \n",
       "178        5.0                   24840              6.900000   \n",
       "179        7.0                   27900              7.750000   \n",
       "180        7.0                   25860              7.183333   \n",
       "\n",
       "     PREV_SLEEP_START  SLEEP_START_VARIABILITY  Is_Weekend  Season  \n",
       "0                 0.0                     22.0           0    Fall  \n",
       "1                22.0                      0.0           0    Fall  \n",
       "2                22.0                      1.0           0    Fall  \n",
       "3                23.0                      1.0           0    Fall  \n",
       "4                22.0                      0.0           0    Fall  \n",
       "..                ...                      ...         ...     ...  \n",
       "176              21.0                      0.0           0  Spring  \n",
       "177              21.0                      0.0           0  Spring  \n",
       "178              21.0                      1.0           0  Spring  \n",
       "179              22.0                      0.0           0  Spring  \n",
       "180              22.0                      1.0           1  Spring  \n",
       "\n",
       "[178 rows x 17 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###more feature engineering \n",
    "\n",
    "#prev sleep diff\n",
    "data['PREV_SLEEP_START'] = data['SLEEP START'].shift(1)\n",
    "data['PREV_SLEEP_START'] = data['SLEEP START'].shift(1).fillna(0)\n",
    "\n",
    "# sleep start var\n",
    "data['SLEEP_START_VARIABILITY'] = (data['SLEEP START'] - data['PREV_SLEEP_START']).abs()\n",
    "data['SLEEP_START_VARIABILITY']  = data['SLEEP_START_VARIABILITY'] .fillna(0)\n",
    "\n",
    "#weekend or not\n",
    "data['Is_Weekend'] = data['Weekday'].isin(['Saturday', 'Sunday']).astype(int)\n",
    "\n",
    "#seasons\n",
    "season_map = {\n",
    "    'December': 'Winter', 'January': 'Winter', 'February': 'Winter',\n",
    "    'March': 'Spring', 'April': 'Spring', 'May': 'Spring',\n",
    "    'June': 'Summer', 'July': 'Summer', 'August': 'Summer',\n",
    "    'September': 'Fall', 'October': 'Fall', 'November': 'Fall'\n",
    "}\n",
    "\n",
    "data['Season'] = data['Month'].map(season_map)\n",
    "\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "#final data Prep \n",
    "\n",
    "\n",
    "# Define the columns\n",
    "numeric_cols = ['SLEEP SCORE', 'REM SLEEP', 'DEEP SLEEP', 'HEART RATE BELOW RESTING', 'SLEEP START', 'SLEEP END', 'SLEEP DURATION SECONDS', 'SLEEP DURATION HOURS', 'SLEEP_START_VARIABILITY', 'PREV_SLEEP_START','Is_Weekend' ]\n",
    "categorical_cols = ['Month', 'Weekday', 'Season']\n",
    "\n",
    "# Define transformers for numeric and categorical columns\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='mean')),  # Handle missing values\n",
    "    ('scaler', StandardScaler())  # Standardize numeric variables\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),  # Handle missing values\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore'))  # One-hot encoding\n",
    "])\n",
    "\n",
    "# Combine transformations in a ColumnTransformer\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_cols),\n",
    "        ('cat', categorical_transformer, categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Apply the transformations to the DataFrame\n",
    "df_transformed = preprocessor.fit_transform(data)\n",
    "\n",
    "# Convert the result back to a DataFrame with appropriate column names\n",
    "# For one-hot encoded columns, the names are generated dynamically\n",
    "categorical_feature_names = preprocessor.transformers_[1][1].named_steps['onehot'].get_feature_names_out(categorical_cols)\n",
    "column_names = numeric_cols + list(categorical_feature_names)\n",
    "\n",
    "df_standardized_encoded = pd.DataFrame(df_transformed, columns=column_names)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select features and target\n",
    "target = \"SLEEP SCORE\"\n",
    "X = df_standardized_encoded.drop(columns=[target])\n",
    "y = df_standardized_encoded[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bagging Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging CV MSE: 0.68\n",
      "CV Standard Deviation (MSE): 0.96\n",
      "Bagging CV R²: 0.492\n",
      "CV Standard Deviation (R²): 0.248\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Create the advanced bagging model using RandomForestRegressor as the base estimator\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=RandomForestRegressor(n_estimators=100, random_state=1),\n",
    "    n_estimators=100,  # Number of bagging iterations\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Perform cross-validation on Bagging model for MSE\n",
    "bagging_cv_mse_scores = cross_val_score(\n",
    "    bagging_model, X, y, cv=3, scoring='neg_mean_squared_error'\n",
    ")\n",
    "bagging_cv_mse = -np.mean(bagging_cv_mse_scores)  # Convert negative MSE to positive\n",
    "bagging_cv_mse_std = np.std(bagging_cv_mse_scores)\n",
    "\n",
    "# Perform cross-validation on Bagging model for R²\n",
    "bagging_cv_r2_scores = cross_val_score(\n",
    "    bagging_model, X, y, cv=5, scoring='r2'\n",
    ")\n",
    "bagging_cv_r2 = np.mean(bagging_cv_r2_scores)\n",
    "bagging_cv_r2_std = np.std(bagging_cv_r2_scores)\n",
    "\n",
    "# Output the cross-validation results\n",
    "print(f\"Bagging CV MSE: {bagging_cv_mse:.2f}\")\n",
    "print(f\"CV Standard Deviation (MSE): {bagging_cv_mse_std:.2f}\")\n",
    "print(f\"Bagging CV R²: {bagging_cv_r2:.3f}\")\n",
    "print(f\"CV Standard Deviation (R²): {bagging_cv_r2_std:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bagging CV MSE: 0.80\n",
      "CV Standard Deviation (MSE): 0.59\n",
      "Bagging CV R²: 0.306\n",
      "CV Standard Deviation (R²): 0.364\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import BaggingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import numpy as np\n",
    "\n",
    "# Create the advanced bagging model using DecisionTreeRegressor as the base estimator\n",
    "bagging_model = BaggingRegressor(\n",
    "    estimator=DecisionTreeRegressor(random_state=1),\n",
    "    n_estimators=100,  # Number of bagging iterations\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "# Perform cross-validation on Bagging model for MSE\n",
    "bagging_cv_mse_scores = cross_val_score(\n",
    "    bagging_model, X, y, cv=3, scoring='neg_mean_squared_error'\n",
    ")\n",
    "bagging_cv_mse = -np.mean(bagging_cv_mse_scores)  # Convert negative MSE to positive\n",
    "bagging_cv_mse_std = np.std(bagging_cv_mse_scores)\n",
    "\n",
    "# Perform cross-validation on Bagging model for R²\n",
    "bagging_cv_r2_scores = cross_val_score(\n",
    "    bagging_model, X, y, cv=5, scoring='r2'\n",
    ")\n",
    "bagging_cv_r2 = np.mean(bagging_cv_r2_scores)\n",
    "bagging_cv_r2_std = np.std(bagging_cv_r2_scores)\n",
    "\n",
    "# Output the cross-validation results\n",
    "print(f\"Bagging CV MSE: {bagging_cv_mse:.2f}\")\n",
    "print(f\"CV Standard Deviation (MSE): {bagging_cv_mse_std:.2f}\")\n",
    "print(f\"Bagging CV R²: {bagging_cv_r2:.3f}\")\n",
    "print(f\"CV Standard Deviation (R²): {bagging_cv_r2_std:.3f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stacking Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.1451374368948915\n",
      "R-squared: 0.785948558182254\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming X_train, X_test, y_train, and y_test are already defined\n",
    "\n",
    "# Define base models for stacking\n",
    "base_models = [\n",
    "    ('lr', LinearRegression()),        # Linear regression\n",
    "    ('dt', DecisionTreeRegressor()),   # Decision tree regressor\n",
    "    ('rf', RandomForestRegressor())    # Random forest regressor\n",
    "]\n",
    "\n",
    "# Define the meta-model\n",
    "meta_model = LinearRegression()\n",
    "\n",
    "# Create the stacking model\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=meta_model)\n",
    "\n",
    "# Train the model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 0.13227985721255153\n",
      "R-squared: 0.8049111603073319\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('ridge', Ridge(alpha=1.0)),  # Ridge regression model\n",
    "    ('svr', SVR(kernel='rbf')),   # Support Vector Regression model\n",
    "    ('rf', RandomForestRegressor(n_estimators=100, random_state=42))  # Random Forest Regressor model\n",
    "]\n",
    "\n",
    "# Final estimator: simple Ridge\n",
    "final_estimator = Ridge(alpha=1.0)\n",
    "\n",
    "# Create the stacking model\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Train-test split\n",
    "target = \"SLEEP SCORE\"\n",
    "X = df_standardized_encoded.drop(columns=[target])\n",
    "y = df_standardized_encoded[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "# Train the model\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'final_estimator__alpha': 0.1, 'rf__max_depth': 10, 'rf__n_estimators': 100, 'ridge__alpha': 1.0, 'svr__C': 1.0, 'svr__gamma': 'auto'}\n",
      "Mean Squared Error: 0.1198975598506005\n",
      "R-squared: 0.823172807061237\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import StackingRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Base models\n",
    "base_models = [\n",
    "    ('ridge', Ridge()),  # Ridge regression model\n",
    "    ('svr', SVR()),      # Support Vector Regression model\n",
    "    ('rf', RandomForestRegressor(random_state=42))  # Random Forest Regressor model\n",
    "]\n",
    "\n",
    "# Final estimator: Ridge (initial choice)\n",
    "final_estimator = Ridge()\n",
    "\n",
    "# Create the stacking model\n",
    "stacking_model = StackingRegressor(estimators=base_models, final_estimator=final_estimator)\n",
    "\n",
    "# Define the hyperparameter grid for base models and final estimator\n",
    "param_grid = {\n",
    "    'ridge__alpha': [0.1, 1.0, 10.0],\n",
    "    'svr__C': [0.1, 1.0, 10.0],\n",
    "    'svr__gamma': ['scale', 'auto'],\n",
    "    'rf__n_estimators': [50, 100, 200],\n",
    "    'rf__max_depth': [None, 10, 20],\n",
    "    'final_estimator__alpha': [0.1, 1.0, 10.0]\n",
    "}\n",
    "\n",
    "# Train-test split\n",
    "target = \"SLEEP SCORE\"\n",
    "X = df_standardized_encoded.drop(columns=[target])\n",
    "y = df_standardized_encoded[target]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=32)\n",
    "\n",
    "# Perform GridSearchCV to tune hyperparameters\n",
    "grid_search = GridSearchCV(estimator=stacking_model, param_grid=param_grid, cv=2, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Best model from GridSearchCV\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Predict using the best model\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error and R-squared\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Print the results\n",
    "print(f\"Best parameters: {grid_search.best_params_}\")\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "print(f\"R-squared: {r2}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best-performing model among all those tested, including stacking and bagging, was the StackingRegressor combining Ridge regression, SVR, and Random Forest, which achieved an impressive R-squared of 0.823. This result makes sense, as stacking typically outperforms bagging. By blending the strengths of different models, stacking captures a wider variety of data patterns, leading to more accurate and robust predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEART RATE BELOW RESTING    0.365402\n",
      "REM SLEEP                   0.209072\n",
      "Weekday_Thursday            0.104761\n",
      "SLEEP DURATION HOURS        0.085880\n",
      "SLEEP DURATION SECONDS      0.078780\n",
      "Month_March                 0.030082\n",
      "DEEP SLEEP                  0.028720\n",
      "SLEEP_START_VARIABILITY     0.014377\n",
      "Season_Winter               0.011888\n",
      "PREV_SLEEP_START            0.011504\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Feature importances (only for models that support it like RandomForest)\n",
    "features = X_train.columns\n",
    "rf_imp = best_model.named_estimators_['rf'].feature_importances_\n",
    "\n",
    "# SVR and Ridge do not have `feature_importances_`, so handle them separately\n",
    "feat_imp = pd.Series(rf_imp, index=features).sort_values(ascending=False)\n",
    "\n",
    "# Print the top 10 feature importances\n",
    "print(feat_imp.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the best stacking model, the strongest numerical predictors of SLEEP SCORE are:\n",
    "\n",
    "HEART RATE BELOW RESTING (0.36) – Higher proportions of time spent below resting heart rate are strongly associated with higher sleep scores.\n",
    "\n",
    "REM SLEEP (0.20) – More REM sleep correlates with better sleep quality, contributing significantly to higher sleep scores.\n",
    "\n",
    "Weekday_Thursday (0.10) – Sleep scores tend to be higher on Thursdays, possibly reflecting weekly sleep pattern trends.\n",
    "\n",
    "SLEEP DURATION HOURS (0.09) – Longer sleep duration in hours has a modest positive effect on sleep scores.\n",
    "\n",
    "SLEEP DURATION SECONDS (0.08) – Consistent with the above, total sleep time in seconds also shows a small positive relationship with sleep scores.\n",
    "\n",
    "DEEP SLEEP (0.03) – Slightly contributes to higher sleep scores, though weaker than REM sleep or total duration.\n",
    "\n",
    "SLEEP_START_VARIABILITY (0.01) – Lower variability in sleep start times is weakly associated with higher sleep scores.\n",
    "\n",
    "Season_Winter (0.01) – Slight seasonal effect; winter shows a marginal positive association with sleep scores.\n",
    "\n",
    "PREV_SLEEP_START (0.01) – The timing of the previous sleep start has a weak positive relationship with the current sleep score.\n",
    "\n",
    "Month_March (0.03) – Marginal seasonal effect; March shows a slight positive association with sleep scores."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
