{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d9378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Core Python & Visualization ----- #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----- Data Preprocessing ----- #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ----- Models ----- #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ----- Evaluation Metrics ----- #\n",
    "from sklearn.metrics import r2_score, mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ----- Neural Network (Keras) ----- #\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18544a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>workclass</th>\n",
       "      <th>fnlwgt</th>\n",
       "      <th>education</th>\n",
       "      <th>education-num</th>\n",
       "      <th>marital-status</th>\n",
       "      <th>occupation</th>\n",
       "      <th>relationship</th>\n",
       "      <th>race</th>\n",
       "      <th>sex</th>\n",
       "      <th>capital-gain</th>\n",
       "      <th>capital-loss</th>\n",
       "      <th>hours-per-week</th>\n",
       "      <th>native-country</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          workclass   fnlwgt   education   education-num  \\\n",
       "0   39          State-gov    77516   Bachelors              13   \n",
       "1   50   Self-emp-not-inc    83311   Bachelors              13   \n",
       "2   38            Private   215646     HS-grad               9   \n",
       "3   53            Private   234721        11th               7   \n",
       "4   28            Private   338409   Bachelors              13   \n",
       "\n",
       "        marital-status          occupation    relationship    race      sex  \\\n",
       "0        Never-married        Adm-clerical   Not-in-family   White     Male   \n",
       "1   Married-civ-spouse     Exec-managerial         Husband   White     Male   \n",
       "2             Divorced   Handlers-cleaners   Not-in-family   White     Male   \n",
       "3   Married-civ-spouse   Handlers-cleaners         Husband   Black     Male   \n",
       "4   Married-civ-spouse      Prof-specialty            Wife   Black   Female   \n",
       "\n",
       "    capital-gain   capital-loss   hours-per-week  native-country  income  \n",
       "0           2174              0               40   United-States   <=50K  \n",
       "1              0              0               13   United-States   <=50K  \n",
       "2              0              0               40   United-States   <=50K  \n",
       "3              0              0               40   United-States   <=50K  \n",
       "4              0              0               40            Cuba   <=50K  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# loading data\n",
    "df = pd.read_csv(\"/Users/anhuynh/Downloads/income_evaluation.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "160db1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some data cleaning\n",
    "df[' income'] = df[' income'].astype(str).str.strip()\n",
    "df[' income'] = df[' income'].map({'>50K': 1, '<=50K': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6e63e054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "income\n",
      "0    24720\n",
      "1     7841\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# First, make sure there are no leading spaces in column names\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "# Now count 0s and 1s\n",
    "print(df['income'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b41b54f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age                  int64\n",
      " workclass          object\n",
      " fnlwgt              int64\n",
      " education          object\n",
      " education-num       int64\n",
      " marital-status     object\n",
      " occupation         object\n",
      " relationship       object\n",
      " race               object\n",
      " sex                object\n",
      " capital-gain        int64\n",
      " capital-loss        int64\n",
      " hours-per-week      int64\n",
      " native-country     object\n",
      " income            float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d484341a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- (1) Load raw data ---- #\n",
    "df = pd.read_csv(\"/Users/anhuynh/Downloads/income_evaluation.csv\")\n",
    "df.columns = df.columns.str.strip()\n",
    "\n",
    "\n",
    "# Clean 'income' column\n",
    "df['income'] = df['income'].astype(str).str.strip()\n",
    "df['income'] = df['income'].map({'>50K': 1, '<=50K': 0})\n",
    "\n",
    "# Now you can split and preprocess!\n",
    "X = df.drop(columns=['income'])\n",
    "y = df['income']\n",
    "\n",
    "\n",
    "categorical_cols = X.select_dtypes(include='object').columns.tolist()\n",
    "numerical_cols = X.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "# ---- (2) Train/test split BEFORE preprocessing ---- #\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ---- (3) Define Preprocessor ---- #\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('num', numerical_transformer, numerical_cols),\n",
    "    ('cat', categorical_transformer, categorical_cols)\n",
    "])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee0ba253",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Logistic Regression model: 0.8582834331337326\n",
      "Confusion matrix of the Logistic Regression model:\n",
      " [[4623  319]\n",
      " [ 604  967]]\n",
      "\n",
      "Classification report of the Logistic Regression model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.94      0.91      4942\n",
      "           1       0.75      0.62      0.68      1571\n",
      "\n",
      "    accuracy                           0.86      6513\n",
      "   macro avg       0.82      0.78      0.79      6513\n",
      "weighted avg       0.85      0.86      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. Define the Logistic Regression model\n",
    "logreg = LogisticRegression(solver='liblinear', random_state=42)\n",
    "\n",
    "# 2. Build the Logistic Regression pipeline\n",
    "log_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # your preprocessor for scaling + encoding\n",
    "    ('classifier', logreg)\n",
    "])\n",
    "\n",
    "# 3. Fit the pipeline\n",
    "log_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_log = log_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Logistic Regression model:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"Confusion matrix of the Logistic Regression model:\\n\", confusion_matrix(y_test, y_pred_log))\n",
    "print(\"\\nClassification report of the Logistic Regression model:\\n\", classification_report(y_test, y_pred_log))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d24b0e9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Decision Tree model: 0.8504529402732995\n",
      "Confusion matrix of the Decision Tree model:\n",
      " [[4724  218]\n",
      " [ 756  815]]\n",
      "\n",
      "Classification report of the Decision Tree model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      4942\n",
      "           1       0.79      0.52      0.63      1571\n",
      "\n",
      "    accuracy                           0.85      6513\n",
      "   macro avg       0.83      0.74      0.77      6513\n",
      "weighted avg       0.84      0.85      0.84      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# 1. Define Decision Tree model\n",
    "dt = DecisionTreeClassifier(max_depth=5, random_state=42)\n",
    "\n",
    "# 2. Build Decision Tree pipeline\n",
    "dt_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', dt)\n",
    "])\n",
    "\n",
    "# 3. Fit\n",
    "dt_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_dt = dt_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Decision Tree model:\", accuracy_score(y_test, y_pred_dt))\n",
    "print(\"Confusion matrix of the Decision Tree model:\\n\", confusion_matrix(y_test, y_pred_dt))\n",
    "print(\"\\nClassification report of the Decision Tree model:\\n\", classification_report(y_test, y_pred_dt))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "f359da5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Random Forest model: 0.8556732688469215\n",
      "Confusion matrix of the Random Forest model:\n",
      " [[4727  215]\n",
      " [ 725  846]]\n",
      "\n",
      "Classification report of the Random Forest model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.96      0.91      4942\n",
      "           1       0.80      0.54      0.64      1571\n",
      "\n",
      "    accuracy                           0.86      6513\n",
      "   macro avg       0.83      0.75      0.78      6513\n",
      "weighted avg       0.85      0.86      0.85      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# 1. Define Random Forest model\n",
    "rf = RandomForestClassifier(n_estimators=100, max_depth=10, random_state=42)\n",
    "\n",
    "# 2. Build Random Forest pipeline\n",
    "rf_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', rf)\n",
    "])\n",
    "\n",
    "# 3. Fit\n",
    "rf_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_rf = rf_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Random Forest model:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion matrix of the Random Forest model:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"\\nClassification report of the Random Forest model:\\n\", classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b4e78c8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Gaussian Naive Bayes model: 0.5312452019038846\n",
      "Confusion matrix of the Gaussian Naive Bayes model:\n",
      " [[1948 2994]\n",
      " [  59 1512]]\n",
      "\n",
      "Classification report of the Gaussian Naive Bayes model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.39      0.56      4942\n",
      "           1       0.34      0.96      0.50      1571\n",
      "\n",
      "    accuracy                           0.53      6513\n",
      "   macro avg       0.65      0.68      0.53      6513\n",
      "weighted avg       0.82      0.53      0.55      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# 2. Build the GNB pipeline\n",
    "log_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # same preprocessor as others\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# 3. Fit the GNB pipeline\n",
    "log_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_gnb = gnb_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Gaussian Naive Bayes model:\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Confusion matrix of the Gaussian Naive Bayes model:\\n\", confusion_matrix(y_test, y_pred_gnb))\n",
    "print(\"\\nClassification report of the Gaussian Naive Bayes model:\\n\", classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57a377b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [17:24:49] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/sklearn/ensemble/_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy: 0.8739444188545985\n",
      "Confusion matrix of the XGboost:\n",
      " [[4641  301]\n",
      " [ 520 1051]]\n",
      "\n",
      "Classification report of the XGboost model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.94      0.92      4942\n",
      "           1       0.78      0.67      0.72      1571\n",
      "\n",
      "    accuracy                           0.87      6513\n",
      "   macro avg       0.84      0.80      0.82      6513\n",
      "weighted avg       0.87      0.87      0.87      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ---- (4) Build Model Pipelines ---- #\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "xgb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', XGBClassifier(use_label_encoder=False, eval_metric='logloss', random_state=42))\n",
    "])\n",
    "\n",
    "ada_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', AdaBoostClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# ---- (5) Train Pipelines ---- #\n",
    "xgb_pipeline.fit(X_train, y_train)\n",
    "ada_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# ---- (6) Predict & Evaluate ---- #\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "xgb_preds = xgb_pipeline.predict(X_test)\n",
    "ada_preds = ada_pipeline.predict(X_test)\n",
    "\n",
    "print(\"XGBoost Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
    "print(\"Confusion matrix of the XGboost:\\n\", confusion_matrix(y_test, xgb_preds))\n",
    "print(\"\\nClassification report of the XGboost model:\\n\", classification_report(y_test, xgb_preds))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "5b3ec2ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost Accuracy: 0.8633502226316597\n",
      "Confusion matrix of the XGboost:\n",
      " [[4637  305]\n",
      " [ 585  986]]\n",
      "\n",
      "Classification report of the XGboost model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.94      0.91      4942\n",
      "           1       0.76      0.63      0.69      1571\n",
      "\n",
      "    accuracy                           0.86      6513\n",
      "   macro avg       0.83      0.78      0.80      6513\n",
      "weighted avg       0.86      0.86      0.86      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"AdaBoost Accuracy:\", accuracy_score(y_test, ada_preds))\n",
    "print(\"Confusion matrix of the XGboost:\\n\", confusion_matrix(y_test, ada_preds))\n",
    "print(\"\\nClassification report of the XGboost model:\\n\", classification_report(y_test, ada_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2c65eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Gaussian Naive Bayes model: 0.5312452019038846\n",
      "Confusion matrix of the Gaussian Naive Bayes model:\n",
      " [[1948 2994]\n",
      " [  59 1512]]\n",
      "\n",
      "Classification report of the Gaussian Naive Bayes model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.39      0.56      4942\n",
      "           1       0.34      0.96      0.50      1571\n",
      "\n",
      "    accuracy                           0.53      6513\n",
      "   macro avg       0.65      0.68      0.53      6513\n",
      "weighted avg       0.82      0.53      0.55      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# 1. Define the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "\n",
    "# 2. Build the GNB pipeline\n",
    "gnb_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # same preprocessor as others\n",
    "    ('classifier', gnb)\n",
    "])\n",
    "\n",
    "# 3. Fit the GNB pipeline\n",
    "gnb_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_gnb = gnb_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Gaussian Naive Bayes model:\", accuracy_score(y_test, y_pred_gnb))\n",
    "print(\"Confusion matrix of the Gaussian Naive Bayes model:\\n\", confusion_matrix(y_test, y_pred_gnb))\n",
    "print(\"\\nClassification report of the Gaussian Naive Bayes model:\\n\", classification_report(y_test, y_pred_gnb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f1d4c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the Neural Network (MLP) model: 0.8369415016121603\n",
      "Confusion matrix of the Neural Network (MLP) model:\n",
      " [[4453  489]\n",
      " [ 573  998]]\n",
      "\n",
      "Classification report of the Neural Network (MLP) model:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.90      0.89      4942\n",
      "           1       0.67      0.64      0.65      1571\n",
      "\n",
      "    accuracy                           0.84      6513\n",
      "   macro avg       0.78      0.77      0.77      6513\n",
      "weighted avg       0.83      0.84      0.84      6513\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "# 1. Define the MLPClassifier\n",
    "mlp = MLPClassifier(hidden_layer_sizes=(100,), max_iter=500, random_state=42)\n",
    "\n",
    "# 2. Build the pipeline\n",
    "mlp_pipeline = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),  # reuse the same preprocessor\n",
    "    ('classifier', mlp)\n",
    "])\n",
    "\n",
    "# 3. Fit the pipeline\n",
    "mlp_pipeline.fit(X_train, y_train)\n",
    "\n",
    "# 4. Predict\n",
    "y_pred_mlp = mlp_pipeline.predict(X_test)\n",
    "\n",
    "# 5. Evaluate\n",
    "print(\"Accuracy of the Neural Network (MLP) model:\", accuracy_score(y_test, y_pred_mlp))\n",
    "print(\"Confusion matrix of the Neural Network (MLP) model:\\n\", confusion_matrix(y_test, y_pred_mlp))\n",
    "print(\"\\nClassification report of the Neural Network (MLP) model:\\n\", classification_report(y_test, y_pred_mlp))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9237178",
   "metadata": {},
   "source": [
    "My XGBoost model demonstrated the strongest performance among all models tested. It achieved a high overall accuracy of 86% in predicting whether an individual earns more or less than $50,000 per year. The model was particularly effective at correctly identifying individuals earning less than $50,000, while also maintaining solid performance in recognizing higher earners. Overall, these results indicate that the model is both reliable and well-balanced, making it the most suitable option for accurately assessing income levels based on the available data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
