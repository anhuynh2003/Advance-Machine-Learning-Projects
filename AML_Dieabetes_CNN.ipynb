{
 "cells": [
  {
   "cell_type": "raw",
   "id": "b5a58be8",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: â€œLab 4â€\n",
    "author: An Huynh\n",
    "format: \n",
    "    html:\n",
    "        toc: true\n",
    "        code-fold: true \n",
    "        code-summary: \"Show code\"\n",
    "embed-resources: true\n",
    "editor: visual\n",
    "execute: \n",
    "    message: false \n",
    "    warning: false\n",
    "theme: flatly \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2fb7fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----- Core Python & Visualization ----- #\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# ----- Data Preprocessing ----- #\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# ----- Models ----- #\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# ----- Evaluation Metrics ----- #\n",
    "from sklearn.metrics import r2_score, mean_squared_error, classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# ----- Neural Network (Keras) ----- #\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam, SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef995937",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253675</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253676</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253677</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253678</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>253679</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253680 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                   0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
       "1                   0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
       "2                   0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
       "3                   0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
       "4                   0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
       "...                 ...     ...       ...        ...   ...     ...     ...   \n",
       "253675              0.0     1.0       1.0        1.0  45.0     0.0     0.0   \n",
       "253676              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "253677              0.0     0.0       0.0        1.0  28.0     0.0     0.0   \n",
       "253678              0.0     1.0       0.0        1.0  23.0     0.0     0.0   \n",
       "253679              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "        HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                        0.0           0.0     0.0  ...            1.0   \n",
       "1                        0.0           1.0     0.0  ...            0.0   \n",
       "2                        0.0           0.0     1.0  ...            1.0   \n",
       "3                        0.0           1.0     1.0  ...            1.0   \n",
       "4                        0.0           1.0     1.0  ...            1.0   \n",
       "...                      ...           ...     ...  ...            ...   \n",
       "253675                   0.0           0.0     1.0  ...            1.0   \n",
       "253676                   0.0           0.0     0.0  ...            1.0   \n",
       "253677                   0.0           1.0     1.0  ...            1.0   \n",
       "253678                   0.0           0.0     1.0  ...            1.0   \n",
       "253679                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "        NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0               0.0      5.0      18.0      15.0       1.0  0.0   9.0   \n",
       "1               1.0      3.0       0.0       0.0       0.0  0.0   7.0   \n",
       "2               1.0      5.0      30.0      30.0       1.0  0.0   9.0   \n",
       "3               0.0      2.0       0.0       0.0       0.0  0.0  11.0   \n",
       "4               0.0      2.0       3.0       0.0       0.0  0.0  11.0   \n",
       "...             ...      ...       ...       ...       ...  ...   ...   \n",
       "253675          0.0      3.0       0.0       5.0       0.0  1.0   5.0   \n",
       "253676          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "253677          0.0      1.0       0.0       0.0       0.0  0.0   2.0   \n",
       "253678          0.0      3.0       0.0       0.0       0.0  1.0   7.0   \n",
       "253679          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "        Education  Income  \n",
       "0             4.0     3.0  \n",
       "1             6.0     1.0  \n",
       "2             4.0     8.0  \n",
       "3             3.0     6.0  \n",
       "4             5.0     4.0  \n",
       "...           ...     ...  \n",
       "253675        6.0     7.0  \n",
       "253676        2.0     4.0  \n",
       "253677        5.0     2.0  \n",
       "253678        5.0     1.0  \n",
       "253679        6.0     2.0  \n",
       "\n",
       "[253680 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df = pd.read_csv(\"/Users/anhuynh/Downloads/diabetes_binary_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16dc6d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ§  Shape of df: (253680, 22)\n",
      "\n",
      "ğŸ“‹ Column names:\n",
      " ['Diabetes_binary', 'HighBP', 'HighChol', 'CholCheck', 'BMI', 'Smoker', 'Stroke', 'HeartDiseaseorAttack', 'PhysActivity', 'Fruits', 'Veggies', 'HvyAlcoholConsump', 'AnyHealthcare', 'NoDocbcCost', 'GenHlth', 'MentHlth', 'PhysHlth', 'DiffWalk', 'Sex', 'Age', 'Education', 'Income']\n",
      "\n",
      "ğŸ” Data types:\n",
      " Diabetes_binary         float64\n",
      "HighBP                  float64\n",
      "HighChol                float64\n",
      "CholCheck               float64\n",
      "BMI                     float64\n",
      "Smoker                  float64\n",
      "Stroke                  float64\n",
      "HeartDiseaseorAttack    float64\n",
      "PhysActivity            float64\n",
      "Fruits                  float64\n",
      "Veggies                 float64\n",
      "HvyAlcoholConsump       float64\n",
      "AnyHealthcare           float64\n",
      "NoDocbcCost             float64\n",
      "GenHlth                 float64\n",
      "MentHlth                float64\n",
      "PhysHlth                float64\n",
      "DiffWalk                float64\n",
      "Sex                     float64\n",
      "Age                     float64\n",
      "Education               float64\n",
      "Income                  float64\n",
      "dtype: object\n",
      "\n",
      "ğŸ§¾ First 5 rows:\n",
      "    Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
      "0              0.0     1.0       1.0        1.0  40.0     1.0     0.0   \n",
      "1              0.0     0.0       0.0        0.0  25.0     1.0     0.0   \n",
      "2              0.0     1.0       1.0        1.0  28.0     0.0     0.0   \n",
      "3              0.0     1.0       0.0        1.0  27.0     0.0     0.0   \n",
      "4              0.0     1.0       1.0        1.0  24.0     0.0     0.0   \n",
      "\n",
      "   HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
      "0                   0.0           0.0     0.0  ...            1.0   \n",
      "1                   0.0           1.0     0.0  ...            0.0   \n",
      "2                   0.0           0.0     1.0  ...            1.0   \n",
      "3                   0.0           1.0     1.0  ...            1.0   \n",
      "4                   0.0           1.0     1.0  ...            1.0   \n",
      "\n",
      "   NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  Education  \\\n",
      "0          0.0      5.0      18.0      15.0       1.0  0.0   9.0        4.0   \n",
      "1          1.0      3.0       0.0       0.0       0.0  0.0   7.0        6.0   \n",
      "2          1.0      5.0      30.0      30.0       1.0  0.0   9.0        4.0   \n",
      "3          0.0      2.0       0.0       0.0       0.0  0.0  11.0        3.0   \n",
      "4          0.0      2.0       3.0       0.0       0.0  0.0  11.0        5.0   \n",
      "\n",
      "   Income  \n",
      "0     3.0  \n",
      "1     1.0  \n",
      "2     8.0  \n",
      "3     6.0  \n",
      "4     4.0  \n",
      "\n",
      "[5 rows x 22 columns]\n",
      "\n",
      "ğŸ§¹ Missing values per column:\n",
      " Diabetes_binary         0\n",
      "HighBP                  0\n",
      "HighChol                0\n",
      "CholCheck               0\n",
      "BMI                     0\n",
      "Smoker                  0\n",
      "Stroke                  0\n",
      "HeartDiseaseorAttack    0\n",
      "PhysActivity            0\n",
      "Fruits                  0\n",
      "Veggies                 0\n",
      "HvyAlcoholConsump       0\n",
      "AnyHealthcare           0\n",
      "NoDocbcCost             0\n",
      "GenHlth                 0\n",
      "MentHlth                0\n",
      "PhysHlth                0\n",
      "DiffWalk                0\n",
      "Sex                     0\n",
      "Age                     0\n",
      "Education               0\n",
      "Income                  0\n",
      "dtype: int64\n",
      "\n",
      "ğŸ“Š Summary stats (numeric):\n",
      "        Diabetes_binary         HighBP       HighChol      CholCheck  \\\n",
      "count    253680.000000  253680.000000  253680.000000  253680.000000   \n",
      "mean          0.139333       0.429001       0.424121       0.962670   \n",
      "std           0.346294       0.494934       0.494210       0.189571   \n",
      "min           0.000000       0.000000       0.000000       0.000000   \n",
      "25%           0.000000       0.000000       0.000000       1.000000   \n",
      "50%           0.000000       0.000000       0.000000       1.000000   \n",
      "75%           0.000000       1.000000       1.000000       1.000000   \n",
      "max           1.000000       1.000000       1.000000       1.000000   \n",
      "\n",
      "                 BMI         Smoker         Stroke  HeartDiseaseorAttack  \\\n",
      "count  253680.000000  253680.000000  253680.000000         253680.000000   \n",
      "mean       28.382364       0.443169       0.040571              0.094186   \n",
      "std         6.608694       0.496761       0.197294              0.292087   \n",
      "min        12.000000       0.000000       0.000000              0.000000   \n",
      "25%        24.000000       0.000000       0.000000              0.000000   \n",
      "50%        27.000000       0.000000       0.000000              0.000000   \n",
      "75%        31.000000       1.000000       0.000000              0.000000   \n",
      "max        98.000000       1.000000       1.000000              1.000000   \n",
      "\n",
      "        PhysActivity         Fruits  ...  AnyHealthcare    NoDocbcCost  \\\n",
      "count  253680.000000  253680.000000  ...  253680.000000  253680.000000   \n",
      "mean        0.756544       0.634256  ...       0.951053       0.084177   \n",
      "std         0.429169       0.481639  ...       0.215759       0.277654   \n",
      "min         0.000000       0.000000  ...       0.000000       0.000000   \n",
      "25%         1.000000       0.000000  ...       1.000000       0.000000   \n",
      "50%         1.000000       1.000000  ...       1.000000       0.000000   \n",
      "75%         1.000000       1.000000  ...       1.000000       0.000000   \n",
      "max         1.000000       1.000000  ...       1.000000       1.000000   \n",
      "\n",
      "             GenHlth       MentHlth       PhysHlth       DiffWalk  \\\n",
      "count  253680.000000  253680.000000  253680.000000  253680.000000   \n",
      "mean        2.511392       3.184772       4.242081       0.168224   \n",
      "std         1.068477       7.412847       8.717951       0.374066   \n",
      "min         1.000000       0.000000       0.000000       0.000000   \n",
      "25%         2.000000       0.000000       0.000000       0.000000   \n",
      "50%         2.000000       0.000000       0.000000       0.000000   \n",
      "75%         3.000000       2.000000       3.000000       0.000000   \n",
      "max         5.000000      30.000000      30.000000       1.000000   \n",
      "\n",
      "                 Sex            Age      Education         Income  \n",
      "count  253680.000000  253680.000000  253680.000000  253680.000000  \n",
      "mean        0.440342       8.032119       5.050434       6.053875  \n",
      "std         0.496429       3.054220       0.985774       2.071148  \n",
      "min         0.000000       1.000000       1.000000       1.000000  \n",
      "25%         0.000000       6.000000       4.000000       5.000000  \n",
      "50%         0.000000       8.000000       5.000000       7.000000  \n",
      "75%         1.000000      10.000000       6.000000       8.000000  \n",
      "max         1.000000      13.000000       6.000000       8.000000  \n",
      "\n",
      "[8 rows x 22 columns]\n",
      "\n",
      "ğŸ”¢ Unique values per column:\n",
      "  - Diabetes_binary: 2 unique values\n",
      "  - HighBP: 2 unique values\n",
      "  - HighChol: 2 unique values\n",
      "  - CholCheck: 2 unique values\n",
      "  - BMI: 84 unique values\n",
      "  - Smoker: 2 unique values\n",
      "  - Stroke: 2 unique values\n",
      "  - HeartDiseaseorAttack: 2 unique values\n",
      "  - PhysActivity: 2 unique values\n",
      "  - Fruits: 2 unique values\n",
      "  - Veggies: 2 unique values\n",
      "  - HvyAlcoholConsump: 2 unique values\n",
      "  - AnyHealthcare: 2 unique values\n",
      "  - NoDocbcCost: 2 unique values\n",
      "  - GenHlth: 5 unique values\n",
      "  - MentHlth: 31 unique values\n",
      "  - PhysHlth: 31 unique values\n",
      "  - DiffWalk: 2 unique values\n",
      "  - Sex: 2 unique values\n",
      "  - Age: 13 unique values\n",
      "  - Education: 6 unique values\n",
      "  - Income: 8 unique values\n",
      "\n",
      "ğŸ“ Number of duplicate rows: 24206\n",
      "ğŸ§® Total number of missing values in df: 0\n"
     ]
    }
   ],
   "source": [
    "# Dataset Overview\n",
    "print(\"ğŸ§  Shape of df:\", df.shape)\n",
    "\n",
    "# Columns and Data Types\n",
    "print(\"\\nğŸ“‹ Column names:\\n\", df.columns.tolist())\n",
    "print(\"\\nğŸ” Data types:\\n\", df.dtypes)\n",
    "\n",
    "# Preview\n",
    "print(\"\\nğŸ§¾ First 5 rows:\\n\", df.head())\n",
    "\n",
    "# Missing Data\n",
    "print(\"\\nğŸ§¹ Missing values per column:\\n\", df.isnull().sum())\n",
    "\n",
    "# Descriptive Stats for Numeric Columns\n",
    "print(\"\\nğŸ“Š Summary stats (numeric):\\n\", df.describe())\n",
    "\n",
    "# Descriptive Stats for Categorical Columns\n",
    "#print(\"\\nğŸ§© Summary stats (categorical):\\n\", df.describe(include=['object', 'category']))\n",
    "\n",
    "# Unique Values Per Column\n",
    "print(\"\\nğŸ”¢ Unique values per column:\")\n",
    "for col in df.columns:\n",
    "    print(f\"  - {col}: {df[col].nunique()} unique values\")\n",
    "\n",
    "# Duplicate Check\n",
    "print(\"\\nğŸ“ Number of duplicate rows:\", df.duplicated().sum())\n",
    "\n",
    "# Total number of missing values\n",
    "total_na = df.isna().sum().sum()\n",
    "print(\"ğŸ§® Total number of missing values in df:\", total_na)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3311013e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Features and target\n",
    "target_col = 'Diabetes_binary'\n",
    "X = df.drop(columns=[target_col])\n",
    "y = df[target_col]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd88063",
   "metadata": {},
   "source": [
    "1st Basic NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa1d888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892us/step - accuracy: 0.8602 - loss: 0.3471 - val_accuracy: 0.8629 - val_loss: 0.3173\n",
      "Epoch 2/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 836us/step - accuracy: 0.8635 - loss: 0.3193 - val_accuracy: 0.8632 - val_loss: 0.3169\n",
      "Epoch 3/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890us/step - accuracy: 0.8642 - loss: 0.3170 - val_accuracy: 0.8627 - val_loss: 0.3166\n",
      "Epoch 4/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 899us/step - accuracy: 0.8657 - loss: 0.3157 - val_accuracy: 0.8641 - val_loss: 0.3160\n",
      "Epoch 5/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8632 - loss: 0.3175 - val_accuracy: 0.8620 - val_loss: 0.3173\n",
      "Epoch 6/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8663 - loss: 0.3139 - val_accuracy: 0.8650 - val_loss: 0.3157\n",
      "Epoch 7/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 0.3157 - val_accuracy: 0.8630 - val_loss: 0.3168\n",
      "Epoch 8/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3111 - val_accuracy: 0.8636 - val_loss: 0.3161\n",
      "Epoch 9/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919us/step - accuracy: 0.8652 - loss: 0.3149 - val_accuracy: 0.8633 - val_loss: 0.3160\n",
      "Epoch 10/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 829us/step - accuracy: 0.8635 - loss: 0.3171 - val_accuracy: 0.8650 - val_loss: 0.3155\n",
      "Epoch 11/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.8639 - loss: 0.3169 - val_accuracy: 0.8635 - val_loss: 0.3160\n",
      "Epoch 12/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 2ms/step - accuracy: 0.8650 - loss: 0.3152 - val_accuracy: 0.8627 - val_loss: 0.3172\n",
      "Epoch 13/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.8660 - loss: 0.3128 - val_accuracy: 0.8632 - val_loss: 0.3158\n",
      "Epoch 14/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 840us/step - accuracy: 0.8657 - loss: 0.3151 - val_accuracy: 0.8632 - val_loss: 0.3159\n",
      "Epoch 15/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8647 - loss: 0.3153 - val_accuracy: 0.8635 - val_loss: 0.3154\n",
      "Epoch 16/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 910us/step - accuracy: 0.8642 - loss: 0.3164 - val_accuracy: 0.8625 - val_loss: 0.3162\n",
      "Epoch 17/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8655 - loss: 0.3139 - val_accuracy: 0.8654 - val_loss: 0.3155\n",
      "Epoch 18/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 9ms/step - accuracy: 0.8658 - loss: 0.3152 - val_accuracy: 0.8644 - val_loss: 0.3158\n",
      "Epoch 19/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.3137 - val_accuracy: 0.8644 - val_loss: 0.3155\n",
      "Epoch 20/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 913us/step - accuracy: 0.8657 - loss: 0.3138 - val_accuracy: 0.8621 - val_loss: 0.3164\n",
      "Epoch 21/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 893us/step - accuracy: 0.8671 - loss: 0.3130 - val_accuracy: 0.8635 - val_loss: 0.3167\n",
      "Epoch 22/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.8642 - loss: 0.3164 - val_accuracy: 0.8641 - val_loss: 0.3155\n",
      "Epoch 23/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 892us/step - accuracy: 0.8656 - loss: 0.3136 - val_accuracy: 0.8620 - val_loss: 0.3179\n",
      "Epoch 24/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 857us/step - accuracy: 0.8661 - loss: 0.3137 - val_accuracy: 0.8654 - val_loss: 0.3150\n",
      "Epoch 25/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 849us/step - accuracy: 0.8652 - loss: 0.3144 - val_accuracy: 0.8631 - val_loss: 0.3159\n",
      "Epoch 26/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 871us/step - accuracy: 0.8638 - loss: 0.3165 - val_accuracy: 0.8648 - val_loss: 0.3155\n",
      "Epoch 27/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.8653 - loss: 0.3138 - val_accuracy: 0.8645 - val_loss: 0.3152\n",
      "Epoch 28/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 3ms/step - accuracy: 0.8651 - loss: 0.3155 - val_accuracy: 0.8634 - val_loss: 0.3161\n",
      "Epoch 29/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 3ms/step - accuracy: 0.8639 - loss: 0.3151 - val_accuracy: 0.8638 - val_loss: 0.3156\n",
      "Epoch 30/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8658 - loss: 0.3132 - val_accuracy: 0.8645 - val_loss: 0.3153\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f001a65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 453us/step\n",
      "Accuracy : 0.8645\n",
      "Precision: 0.6012\n",
      "Recall   : 0.0819\n",
      "F1 Score : 0.1442\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Get predicted probabilities and convert to binary predictions\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc5e414",
   "metadata": {},
   "source": [
    "This basic neural network model performed well in terms of accuracy but not F1 score, which can be misleading given the urgency and sensitivity of medical diagnoses. Itâ€™s important to explore additional models to better align with the datasetâ€™s intended use to carefully and thoughtfully support accurate patient diagnoses."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47db2a5",
   "metadata": {},
   "source": [
    "2nd More in depth NN model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b2bbdcf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 1ms/step - accuracy: 0.8625 - loss: 0.3282 - val_accuracy: 0.8646 - val_loss: 0.3162\n",
      "Epoch 2/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.8658 - loss: 0.3154 - val_accuracy: 0.8632 - val_loss: 0.3174\n",
      "Epoch 3/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 968us/step - accuracy: 0.8657 - loss: 0.3154 - val_accuracy: 0.8660 - val_loss: 0.3150\n",
      "Epoch 4/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956us/step - accuracy: 0.8647 - loss: 0.3157 - val_accuracy: 0.8639 - val_loss: 0.3165\n",
      "Epoch 5/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 956us/step - accuracy: 0.8671 - loss: 0.3129 - val_accuracy: 0.8656 - val_loss: 0.3157\n",
      "Epoch 6/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 969us/step - accuracy: 0.8669 - loss: 0.3136 - val_accuracy: 0.8646 - val_loss: 0.3154\n",
      "Epoch 7/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3141 - val_accuracy: 0.8653 - val_loss: 0.3152\n",
      "Epoch 8/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1ms/step - accuracy: 0.8671 - loss: 0.3127 - val_accuracy: 0.8656 - val_loss: 0.3150\n",
      "Epoch 9/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8672 - loss: 0.3129 - val_accuracy: 0.8654 - val_loss: 0.3162\n",
      "Epoch 10/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8670 - loss: 0.3140 - val_accuracy: 0.8656 - val_loss: 0.3169\n",
      "Epoch 11/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 998us/step - accuracy: 0.8679 - loss: 0.3111 - val_accuracy: 0.8660 - val_loss: 0.3163\n",
      "Epoch 12/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 979us/step - accuracy: 0.8673 - loss: 0.3120 - val_accuracy: 0.8642 - val_loss: 0.3185\n",
      "Epoch 13/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8677 - loss: 0.3115 - val_accuracy: 0.8641 - val_loss: 0.3171\n",
      "Epoch 14/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 960us/step - accuracy: 0.8668 - loss: 0.3120 - val_accuracy: 0.8646 - val_loss: 0.3149\n",
      "Epoch 15/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 999us/step - accuracy: 0.8668 - loss: 0.3128 - val_accuracy: 0.8642 - val_loss: 0.3176\n",
      "Epoch 16/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 977us/step - accuracy: 0.8687 - loss: 0.3098 - val_accuracy: 0.8646 - val_loss: 0.3154\n",
      "Epoch 17/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 977us/step - accuracy: 0.8675 - loss: 0.3116 - val_accuracy: 0.8643 - val_loss: 0.3165\n",
      "Epoch 18/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 969us/step - accuracy: 0.8667 - loss: 0.3128 - val_accuracy: 0.8635 - val_loss: 0.3153\n",
      "Epoch 19/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8678 - loss: 0.3110 - val_accuracy: 0.8649 - val_loss: 0.3168\n",
      "Epoch 20/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 981us/step - accuracy: 0.8694 - loss: 0.3090 - val_accuracy: 0.8647 - val_loss: 0.3158\n",
      "Epoch 21/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 2ms/step - accuracy: 0.8685 - loss: 0.3111 - val_accuracy: 0.8643 - val_loss: 0.3160\n",
      "Epoch 22/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m271s\u001b[0m 43ms/step - accuracy: 0.8696 - loss: 0.3092 - val_accuracy: 0.8645 - val_loss: 0.3165\n",
      "Epoch 23/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8682 - loss: 0.3099 - val_accuracy: 0.8635 - val_loss: 0.3155\n",
      "Epoch 24/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 985us/step - accuracy: 0.8684 - loss: 0.3118 - val_accuracy: 0.8648 - val_loss: 0.3155\n",
      "Epoch 25/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 990us/step - accuracy: 0.8689 - loss: 0.3110 - val_accuracy: 0.8643 - val_loss: 0.3172\n",
      "Epoch 26/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.8691 - loss: 0.3098 - val_accuracy: 0.8646 - val_loss: 0.3161\n",
      "Epoch 27/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 985us/step - accuracy: 0.8676 - loss: 0.3108 - val_accuracy: 0.8648 - val_loss: 0.3153\n",
      "Epoch 28/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 975us/step - accuracy: 0.8674 - loss: 0.3120 - val_accuracy: 0.8650 - val_loss: 0.3159\n",
      "Epoch 29/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 962us/step - accuracy: 0.8675 - loss: 0.3122 - val_accuracy: 0.8641 - val_loss: 0.3164\n",
      "Epoch 30/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 984us/step - accuracy: 0.8687 - loss: 0.3096 - val_accuracy: 0.8646 - val_loss: 0.3171\n",
      "Accuracy : 0.7211\n",
      "Precision: 0.3063\n",
      "Recall   : 0.7920\n",
      "F1 Score : 0.4417\n"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d2e99e",
   "metadata": {},
   "source": [
    "NN model with class wieights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4920edd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7683 - loss: 0.5297 - val_accuracy: 0.7228 - val_loss: 0.4898\n",
      "Epoch 2/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7222 - loss: 0.5098 - val_accuracy: 0.7281 - val_loss: 0.4775\n",
      "Epoch 3/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 866us/step - accuracy: 0.7221 - loss: 0.5078 - val_accuracy: 0.7232 - val_loss: 0.4939\n",
      "Epoch 4/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 868us/step - accuracy: 0.7201 - loss: 0.5060 - val_accuracy: 0.7153 - val_loss: 0.4969\n",
      "Epoch 5/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 922us/step - accuracy: 0.7203 - loss: 0.5097 - val_accuracy: 0.7279 - val_loss: 0.4750\n",
      "Epoch 6/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 856us/step - accuracy: 0.7198 - loss: 0.5076 - val_accuracy: 0.7297 - val_loss: 0.4846\n",
      "Epoch 7/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 840us/step - accuracy: 0.7220 - loss: 0.5066 - val_accuracy: 0.7184 - val_loss: 0.5026\n",
      "Epoch 8/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - accuracy: 0.7199 - loss: 0.5047 - val_accuracy: 0.7072 - val_loss: 0.5069\n",
      "Epoch 9/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 852us/step - accuracy: 0.7152 - loss: 0.5086 - val_accuracy: 0.7182 - val_loss: 0.5091\n",
      "Epoch 10/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 944us/step - accuracy: 0.7196 - loss: 0.5073 - val_accuracy: 0.7163 - val_loss: 0.5097\n",
      "Epoch 11/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 877us/step - accuracy: 0.7180 - loss: 0.5082 - val_accuracy: 0.7119 - val_loss: 0.5228\n",
      "Epoch 12/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 883us/step - accuracy: 0.7245 - loss: 0.5052 - val_accuracy: 0.7247 - val_loss: 0.4871\n",
      "Epoch 13/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.7159 - loss: 0.5085 - val_accuracy: 0.7378 - val_loss: 0.4773\n",
      "Epoch 14/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 919us/step - accuracy: 0.7217 - loss: 0.5106 - val_accuracy: 0.7260 - val_loss: 0.5003\n",
      "Epoch 15/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 894us/step - accuracy: 0.7202 - loss: 0.5071 - val_accuracy: 0.7237 - val_loss: 0.4983\n",
      "Epoch 16/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 882us/step - accuracy: 0.7205 - loss: 0.5067 - val_accuracy: 0.7149 - val_loss: 0.5008\n",
      "Epoch 17/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867us/step - accuracy: 0.7171 - loss: 0.5088 - val_accuracy: 0.7255 - val_loss: 0.4866\n",
      "Epoch 18/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 870us/step - accuracy: 0.7177 - loss: 0.5094 - val_accuracy: 0.7159 - val_loss: 0.5107\n",
      "Epoch 19/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890us/step - accuracy: 0.7183 - loss: 0.5079 - val_accuracy: 0.7230 - val_loss: 0.5228\n",
      "Epoch 20/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7231 - loss: 0.5098 - val_accuracy: 0.7097 - val_loss: 0.5159\n",
      "Epoch 21/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 918us/step - accuracy: 0.7163 - loss: 0.5077 - val_accuracy: 0.7184 - val_loss: 0.5064\n",
      "Epoch 22/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 951us/step - accuracy: 0.7174 - loss: 0.5078 - val_accuracy: 0.7254 - val_loss: 0.4894\n",
      "Epoch 23/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 1ms/step - accuracy: 0.7207 - loss: 0.5065 - val_accuracy: 0.7174 - val_loss: 0.5076\n",
      "Epoch 24/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 863us/step - accuracy: 0.7220 - loss: 0.5065 - val_accuracy: 0.7301 - val_loss: 0.4809\n",
      "Epoch 25/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 861us/step - accuracy: 0.7185 - loss: 0.5092 - val_accuracy: 0.7245 - val_loss: 0.4900\n",
      "Epoch 26/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 867us/step - accuracy: 0.7201 - loss: 0.5068 - val_accuracy: 0.7302 - val_loss: 0.4775\n",
      "Epoch 27/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 863us/step - accuracy: 0.7219 - loss: 0.5052 - val_accuracy: 0.7161 - val_loss: 0.5014\n",
      "Epoch 28/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 900us/step - accuracy: 0.7161 - loss: 0.5087 - val_accuracy: 0.7295 - val_loss: 0.4891\n",
      "Epoch 29/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 890us/step - accuracy: 0.7189 - loss: 0.5072 - val_accuracy: 0.7154 - val_loss: 0.5233\n",
      "Epoch 30/30\n",
      "\u001b[1m6342/6342\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 1ms/step - accuracy: 0.7206 - loss: 0.5082 - val_accuracy: 0.7224 - val_loss: 0.5015\n",
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 342us/step\n",
      "F1 Score: 0.44292381931809194\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "import numpy as np\n",
    "\n",
    "# Compute class weights\n",
    "weights = class_weight.compute_class_weight(\n",
    "    class_weight='balanced',\n",
    "    classes=np.unique(y_train),\n",
    "    y=y_train\n",
    ")\n",
    "\n",
    "class_weights = dict(enumerate(weights))\n",
    "\n",
    "# Train with class weights\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=1,\n",
    "                    class_weight=class_weights)\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# After training\n",
    "y_pred_probs = model.predict(X_test_scaled)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f1428f46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy : 0.7224\n",
      "Precision: 0.3074\n",
      "Recall   : 0.7920\n",
      "F1 Score : 0.4429\n"
     ]
    }
   ],
   "source": [
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15976c2d",
   "metadata": {},
   "source": [
    "This was the best-performing model in terms of both accuracy and F1 score. Its strong performance may be attributed to its deeper architecture, with 128 and 64 units in the hidden layers, providing sufficient capacity to learn complex patterns within the data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45cd4b01",
   "metadata": {},
   "source": [
    "NN model with Random oversampler - an alternative to smote "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3a8b68b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 842us/step - accuracy: 0.7304 - loss: 0.5368 - val_accuracy: 0.6955 - val_loss: 0.5125\n",
      "Epoch 2/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 857us/step - accuracy: 0.7510 - loss: 0.5084 - val_accuracy: 0.6939 - val_loss: 0.5275\n",
      "Epoch 3/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 1ms/step - accuracy: 0.7516 - loss: 0.5083 - val_accuracy: 0.7087 - val_loss: 0.5045\n",
      "Epoch 4/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 820us/step - accuracy: 0.7525 - loss: 0.5065 - val_accuracy: 0.7085 - val_loss: 0.5060\n",
      "Epoch 5/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840us/step - accuracy: 0.7507 - loss: 0.5074 - val_accuracy: 0.7005 - val_loss: 0.5241\n",
      "Epoch 6/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 817us/step - accuracy: 0.7514 - loss: 0.5072 - val_accuracy: 0.6949 - val_loss: 0.5198\n",
      "Epoch 7/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 831us/step - accuracy: 0.7514 - loss: 0.5061 - val_accuracy: 0.7046 - val_loss: 0.5295\n",
      "Epoch 8/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 825us/step - accuracy: 0.7517 - loss: 0.5061 - val_accuracy: 0.7040 - val_loss: 0.5167\n",
      "Epoch 9/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 831us/step - accuracy: 0.7512 - loss: 0.5065 - val_accuracy: 0.7005 - val_loss: 0.5155\n",
      "Epoch 10/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 891us/step - accuracy: 0.7510 - loss: 0.5057 - val_accuracy: 0.7099 - val_loss: 0.5312\n",
      "Epoch 11/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 844us/step - accuracy: 0.7508 - loss: 0.5067 - val_accuracy: 0.7046 - val_loss: 0.5080\n",
      "Epoch 12/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 839us/step - accuracy: 0.7511 - loss: 0.5059 - val_accuracy: 0.7100 - val_loss: 0.5092\n",
      "Epoch 13/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 834us/step - accuracy: 0.7518 - loss: 0.5059 - val_accuracy: 0.7162 - val_loss: 0.5103\n",
      "Epoch 14/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 839us/step - accuracy: 0.7509 - loss: 0.5059 - val_accuracy: 0.7130 - val_loss: 0.4973\n",
      "Epoch 15/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 834us/step - accuracy: 0.7525 - loss: 0.5048 - val_accuracy: 0.7150 - val_loss: 0.5026\n",
      "Epoch 16/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 887us/step - accuracy: 0.7537 - loss: 0.5038 - val_accuracy: 0.7178 - val_loss: 0.4890\n",
      "Epoch 17/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 830us/step - accuracy: 0.7525 - loss: 0.5044 - val_accuracy: 0.7145 - val_loss: 0.5200\n",
      "Epoch 18/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 847us/step - accuracy: 0.7509 - loss: 0.5055 - val_accuracy: 0.7221 - val_loss: 0.4989\n",
      "Epoch 19/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 849us/step - accuracy: 0.7535 - loss: 0.5049 - val_accuracy: 0.7056 - val_loss: 0.5262\n",
      "Epoch 20/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 841us/step - accuracy: 0.7524 - loss: 0.5045 - val_accuracy: 0.7134 - val_loss: 0.5046\n",
      "Epoch 21/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 846us/step - accuracy: 0.7515 - loss: 0.5056 - val_accuracy: 0.7048 - val_loss: 0.5238\n",
      "Epoch 22/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 840us/step - accuracy: 0.7526 - loss: 0.5043 - val_accuracy: 0.7012 - val_loss: 0.5241\n",
      "Epoch 23/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 911us/step - accuracy: 0.7527 - loss: 0.5037 - val_accuracy: 0.7025 - val_loss: 0.5286\n",
      "Epoch 24/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 849us/step - accuracy: 0.7526 - loss: 0.5043 - val_accuracy: 0.7204 - val_loss: 0.5083\n",
      "Epoch 25/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 869us/step - accuracy: 0.7526 - loss: 0.5040 - val_accuracy: 0.7068 - val_loss: 0.5110\n",
      "Epoch 26/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 835us/step - accuracy: 0.7535 - loss: 0.5043 - val_accuracy: 0.7170 - val_loss: 0.5009\n",
      "Epoch 27/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 834us/step - accuracy: 0.7531 - loss: 0.5042 - val_accuracy: 0.7068 - val_loss: 0.5115\n",
      "Epoch 28/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 874us/step - accuracy: 0.7510 - loss: 0.5071 - val_accuracy: 0.7062 - val_loss: 0.5160\n",
      "Epoch 29/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 906us/step - accuracy: 0.7528 - loss: 0.5059 - val_accuracy: 0.7059 - val_loss: 0.5140\n",
      "Epoch 30/30\n",
      "\u001b[1m10917/10917\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 827us/step - accuracy: 0.7535 - loss: 0.5039 - val_accuracy: 0.7143 - val_loss: 0.5214\n",
      "\u001b[1m1586/1586\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 370us/step\n",
      "Accuracy: 0.7142660044150111\n",
      "Precision: 0.3025728258558367\n",
      "Recall: 0.8052058282642524\n",
      "F1 Score: 0.43985935628453304\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.957     0.700     0.808     43667\n",
      "           1      0.303     0.805     0.440      7069\n",
      "\n",
      "    accuracy                          0.714     50736\n",
      "   macro avg      0.630     0.752     0.624     50736\n",
      "weighted avg      0.866     0.714     0.757     50736\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30547 13120]\n",
      " [ 1377  5692]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# --- Apply Random OverSampler (ROS) ---\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# ---  Build Neural Network ---\n",
    "model = Sequential([\n",
    "    Dense(32, activation='relu', input_shape=(X_train_resampled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Binary output\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# ---  Train Model ---\n",
    "history = model.fit(X_train_resampled, y_train_resampled,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n",
    "# ---  Evaluate on Test Set ---\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# ---  Print Evaluation Metrics ---\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a123c1e8",
   "metadata": {},
   "source": [
    "The neural network model with RandomOverSampler (ROS) achieved the second highest F1 score among all models, making it the best overall performer. This is particularly important in healthcare, where recall is critical â€” missing a diabetic patient (a false negative) can have serious consequences. At the same time, maintaining precision is also essential to avoid unnecessary tests and stress caused by false positives.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "408ea2e3",
   "metadata": {},
   "source": [
    "XGB classification model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2eb16d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/xgboost/core.py:158: UserWarning: [20:40:12] WARNING: /Users/runner/work/xgboost/xgboost/src/learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7210659098076316\n",
      "Precision: 0.3062742738362234\n",
      "Recall: 0.7920497948790494\n",
      "F1 Score: 0.4417357001972387\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0      0.955     0.710     0.814     43667\n",
      "           1      0.306     0.792     0.442      7069\n",
      "\n",
      "    accuracy                          0.721     50736\n",
      "   macro avg      0.630     0.751     0.628     50736\n",
      "weighted avg      0.864     0.721     0.762     50736\n",
      "\n",
      "Confusion Matrix:\n",
      " [[30985 12682]\n",
      " [ 1470  5599]]\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "\n",
    "# ---  Train XGBoost Classifier ---\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.1,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss',\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "xgb_model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# ---  Predict and Evaluate ---\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Precision:\", precision_score(y_test, y_pred))\n",
    "print(\"Recall:\", recall_score(y_test, y_pred))\n",
    "print(\"F1 Score:\", f1_score(y_test, y_pred))\n",
    "\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, digits=3))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d24b0cf",
   "metadata": {},
   "source": [
    "The XGBoost model performed reasonably well compared to the neural network. However, its F1 score and accuracy were slightly lower, making it a less optimal performer overall."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0773f394",
   "metadata": {},
   "source": [
    "Balanced Dataset - Basic NN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a0138ef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Diabetes_binary</th>\n",
       "      <th>HighBP</th>\n",
       "      <th>HighChol</th>\n",
       "      <th>CholCheck</th>\n",
       "      <th>BMI</th>\n",
       "      <th>Smoker</th>\n",
       "      <th>Stroke</th>\n",
       "      <th>HeartDiseaseorAttack</th>\n",
       "      <th>PhysActivity</th>\n",
       "      <th>Fruits</th>\n",
       "      <th>...</th>\n",
       "      <th>AnyHealthcare</th>\n",
       "      <th>NoDocbcCost</th>\n",
       "      <th>GenHlth</th>\n",
       "      <th>MentHlth</th>\n",
       "      <th>PhysHlth</th>\n",
       "      <th>DiffWalk</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Education</th>\n",
       "      <th>Income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70687</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70688</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70689</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70690</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70691</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70692 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Diabetes_binary  HighBP  HighChol  CholCheck   BMI  Smoker  Stroke  \\\n",
       "0                  0.0     1.0       0.0        1.0  26.0     0.0     0.0   \n",
       "1                  0.0     1.0       1.0        1.0  26.0     1.0     1.0   \n",
       "2                  0.0     0.0       0.0        1.0  26.0     0.0     0.0   \n",
       "3                  0.0     1.0       1.0        1.0  28.0     1.0     0.0   \n",
       "4                  0.0     0.0       0.0        1.0  29.0     1.0     0.0   \n",
       "...                ...     ...       ...        ...   ...     ...     ...   \n",
       "70687              1.0     0.0       1.0        1.0  37.0     0.0     0.0   \n",
       "70688              1.0     0.0       1.0        1.0  29.0     1.0     0.0   \n",
       "70689              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "70690              1.0     1.0       1.0        1.0  18.0     0.0     0.0   \n",
       "70691              1.0     1.0       1.0        1.0  25.0     0.0     0.0   \n",
       "\n",
       "       HeartDiseaseorAttack  PhysActivity  Fruits  ...  AnyHealthcare  \\\n",
       "0                       0.0           1.0     0.0  ...            1.0   \n",
       "1                       0.0           0.0     1.0  ...            1.0   \n",
       "2                       0.0           1.0     1.0  ...            1.0   \n",
       "3                       0.0           1.0     1.0  ...            1.0   \n",
       "4                       0.0           1.0     1.0  ...            1.0   \n",
       "...                     ...           ...     ...  ...            ...   \n",
       "70687                   0.0           0.0     0.0  ...            1.0   \n",
       "70688                   1.0           0.0     1.0  ...            1.0   \n",
       "70689                   1.0           0.0     1.0  ...            1.0   \n",
       "70690                   0.0           0.0     0.0  ...            1.0   \n",
       "70691                   1.0           1.0     1.0  ...            1.0   \n",
       "\n",
       "       NoDocbcCost  GenHlth  MentHlth  PhysHlth  DiffWalk  Sex   Age  \\\n",
       "0              0.0      3.0       5.0      30.0       0.0  1.0   4.0   \n",
       "1              0.0      3.0       0.0       0.0       0.0  1.0  12.0   \n",
       "2              0.0      1.0       0.0      10.0       0.0  1.0  13.0   \n",
       "3              0.0      3.0       0.0       3.0       0.0  1.0  11.0   \n",
       "4              0.0      2.0       0.0       0.0       0.0  0.0   8.0   \n",
       "...            ...      ...       ...       ...       ...  ...   ...   \n",
       "70687          0.0      4.0       0.0       0.0       0.0  0.0   6.0   \n",
       "70688          0.0      2.0       0.0       0.0       1.0  1.0  10.0   \n",
       "70689          0.0      5.0      15.0       0.0       1.0  0.0  13.0   \n",
       "70690          0.0      4.0       0.0       0.0       1.0  0.0  11.0   \n",
       "70691          0.0      2.0       0.0       0.0       0.0  0.0   9.0   \n",
       "\n",
       "       Education  Income  \n",
       "0            6.0     8.0  \n",
       "1            6.0     8.0  \n",
       "2            6.0     8.0  \n",
       "3            6.0     8.0  \n",
       "4            5.0     8.0  \n",
       "...          ...     ...  \n",
       "70687        4.0     1.0  \n",
       "70688        3.0     6.0  \n",
       "70689        6.0     4.0  \n",
       "70690        2.0     4.0  \n",
       "70691        6.0     2.0  \n",
       "\n",
       "[70692 rows x 22 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd \n",
    "\n",
    "df_balanced = pd.read_csv(\"/Users/anhuynh/Downloads/diabetes_binary_5050split_health_indicators_BRFSS2015.csv\")\n",
    "\n",
    "df_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f36fe64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Features and target\n",
    "target_col = 'Diabetes_binary'\n",
    "X = df_balanced.drop(columns=[target_col])\n",
    "y = df_balanced[target_col]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd250c1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.7343 - loss: 0.5335 - val_accuracy: 0.7487 - val_loss: 0.5047\n",
      "Epoch 2/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7482 - loss: 0.5132 - val_accuracy: 0.7519 - val_loss: 0.5059\n",
      "Epoch 3/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7517 - loss: 0.5099 - val_accuracy: 0.7517 - val_loss: 0.5020\n",
      "Epoch 4/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7541 - loss: 0.5064 - val_accuracy: 0.7508 - val_loss: 0.5014\n",
      "Epoch 5/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7575 - loss: 0.5020 - val_accuracy: 0.7516 - val_loss: 0.5019\n",
      "Epoch 6/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7568 - loss: 0.5005 - val_accuracy: 0.7528 - val_loss: 0.5015\n",
      "Epoch 7/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7550 - loss: 0.5051 - val_accuracy: 0.7511 - val_loss: 0.5022\n",
      "Epoch 8/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7546 - loss: 0.5027 - val_accuracy: 0.7513 - val_loss: 0.5022\n",
      "Epoch 9/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7518 - loss: 0.5058 - val_accuracy: 0.7505 - val_loss: 0.5021\n",
      "Epoch 10/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7574 - loss: 0.5017 - val_accuracy: 0.7518 - val_loss: 0.5011\n",
      "Epoch 11/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.5018 - val_accuracy: 0.7512 - val_loss: 0.5019\n",
      "Epoch 12/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7537 - loss: 0.5022 - val_accuracy: 0.7490 - val_loss: 0.5039\n",
      "Epoch 13/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7581 - loss: 0.4985 - val_accuracy: 0.7491 - val_loss: 0.5053\n",
      "Epoch 14/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7555 - loss: 0.5019 - val_accuracy: 0.7492 - val_loss: 0.5018\n",
      "Epoch 15/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7563 - loss: 0.4996 - val_accuracy: 0.7510 - val_loss: 0.5006\n",
      "Epoch 16/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7583 - loss: 0.4971 - val_accuracy: 0.7515 - val_loss: 0.5013\n",
      "Epoch 17/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7587 - loss: 0.4969 - val_accuracy: 0.7505 - val_loss: 0.5029\n",
      "Epoch 18/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7543 - loss: 0.4987 - val_accuracy: 0.7510 - val_loss: 0.5025\n",
      "Epoch 19/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7600 - loss: 0.4948 - val_accuracy: 0.7505 - val_loss: 0.5021\n",
      "Epoch 20/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7607 - loss: 0.4927 - val_accuracy: 0.7476 - val_loss: 0.5034\n",
      "Epoch 21/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7577 - loss: 0.4960 - val_accuracy: 0.7493 - val_loss: 0.5031\n",
      "Epoch 22/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7551 - loss: 0.4990 - val_accuracy: 0.7475 - val_loss: 0.5036\n",
      "Epoch 23/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.7597 - loss: 0.4960 - val_accuracy: 0.7491 - val_loss: 0.5046\n",
      "Epoch 24/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7613 - loss: 0.4945 - val_accuracy: 0.7492 - val_loss: 0.5035\n",
      "Epoch 25/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7587 - loss: 0.4959 - val_accuracy: 0.7487 - val_loss: 0.5026\n",
      "Epoch 26/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7567 - loss: 0.4956 - val_accuracy: 0.7515 - val_loss: 0.5046\n",
      "Epoch 27/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7605 - loss: 0.4960 - val_accuracy: 0.7494 - val_loss: 0.5030\n",
      "Epoch 28/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7616 - loss: 0.4915 - val_accuracy: 0.7505 - val_loss: 0.5036\n",
      "Epoch 29/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7622 - loss: 0.4935 - val_accuracy: 0.7487 - val_loss: 0.5033\n",
      "Epoch 30/30\n",
      "\u001b[1m1768/1768\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.7585 - loss: 0.4932 - val_accuracy: 0.7486 - val_loss: 0.5035\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [14139, 50736]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 23\u001b[0m\n\u001b[1;32m     16\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(X_train_scaled, y_train,\n\u001b[1;32m     17\u001b[0m                     validation_data\u001b[38;5;241m=\u001b[39m(X_test_scaled, y_test),\n\u001b[1;32m     18\u001b[0m                     epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m,\n\u001b[1;32m     19\u001b[0m                     batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m,\n\u001b[1;32m     20\u001b[0m                     verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Evaluate\u001b[39;00m\n\u001b[0;32m---> 23\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(y_test, y_pred)\n\u001b[1;32m     24\u001b[0m precision \u001b[38;5;241m=\u001b[39m precision_score(y_test, y_pred)\n\u001b[1;32m     25\u001b[0m recall \u001b[38;5;241m=\u001b[39m recall_score(y_test, y_pred)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:213\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    207\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m    209\u001b[0m         skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    210\u001b[0m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    211\u001b[0m         )\n\u001b[1;32m    212\u001b[0m     ):\n\u001b[0;32m--> 213\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    219\u001b[0m     msg \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\n\u001b[1;32m    220\u001b[0m         \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mw+ must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    221\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must be\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    222\u001b[0m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[1;32m    223\u001b[0m     )\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:213\u001b[0m, in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Accuracy classification score.\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \n\u001b[1;32m    149\u001b[0m \u001b[38;5;124;03mIn multilabel classification, this function computes subset accuracy:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m0.5\u001b[39;00m\n\u001b[1;32m    210\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# Compute accuracy for each possible representation\u001b[39;00m\n\u001b[0;32m--> 213\u001b[0m y_type, y_true, y_pred \u001b[38;5;241m=\u001b[39m _check_targets(y_true, y_pred)\n\u001b[1;32m    214\u001b[0m check_consistent_length(y_true, y_pred, sample_weight)\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y_type\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultilabel\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/metrics/_classification.py:85\u001b[0m, in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_targets\u001b[39m(y_true, y_pred):\n\u001b[1;32m     59\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Check that y_true and y_pred belong to the same classification task.\u001b[39;00m\n\u001b[1;32m     60\u001b[0m \n\u001b[1;32m     61\u001b[0m \u001b[38;5;124;03m    This converts multiclass or binary types to a common shape, and raises a\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;124;03m    y_pred : array or indicator matrix\u001b[39;00m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m     check_consistent_length(y_true, y_pred)\n\u001b[1;32m     86\u001b[0m     type_true \u001b[38;5;241m=\u001b[39m type_of_target(y_true, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_true\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     87\u001b[0m     type_pred \u001b[38;5;241m=\u001b[39m type_of_target(y_pred, input_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124my_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/anaconda3/lib/python3.12/site-packages/sklearn/utils/validation.py:457\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    455\u001b[0m uniques \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39munique(lengths)\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(uniques) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    459\u001b[0m         \u001b[38;5;241m%\u001b[39m [\u001b[38;5;28mint\u001b[39m(l) \u001b[38;5;28;01mfor\u001b[39;00m l \u001b[38;5;129;01min\u001b[39;00m lengths]\n\u001b[1;32m    460\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [14139, 50736]"
     ]
    }
   ],
   "source": [
    "# Build the neural network\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(X_train_scaled.shape[1],)),\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train_scaled, y_train,\n",
    "                    validation_data=(X_test_scaled, y_test),\n",
    "                    epochs=30,\n",
    "                    batch_size=32,\n",
    "                    verbose=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "576aaa15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m442/442\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 620us/step\n",
      "Accuracy : 0.5007\n",
      "Precision: 0.5003\n",
      "Recall   : 1.0000\n",
      "F1 Score : 0.6669\n"
     ]
    }
   ],
   "source": [
    "# ---  Evaluate on Test Set ---\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = (y_pred_probs > 0.5).astype(int)\n",
    "\n",
    "# Evaluate\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Display results\n",
    "print(f\"Accuracy : {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall   : {recall:.4f}\")\n",
    "print(f\"F1 Score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a31f07",
   "metadata": {},
   "source": [
    "With a balanced dataset, the F1 score becomes less critical. Although the deeper neural network performs better in terms of recall, it stil not highly effective in accurately diagnosing diabetic patients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba20982",
   "metadata": {},
   "source": [
    "After testing two neural network architectures of varying depth, experimenting with two class balancing techniques, a new nn model with the balanced dataset, and comparing performance with an XGBoost model, I found that the best-performing model was the deep neural network with a unbalanced dataset. This model achieved an accuracy of 72.11%, a precision of 30.63%, a recall of 79.20%, and an F1 score of 44.17%. These results indicate that it was effective at identifying diabetic patients while also being mindful of medical resource constraints by balancing sensitivity with precision."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
