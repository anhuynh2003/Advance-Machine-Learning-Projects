{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85399e79",
   "metadata": {},
   "source": [
    "Today, we will be trying to classify photos by which photographer took them, using CNN models! We have Alex, Kelly, and Hunter as our photographers, and our goal is to be able to predict which photographer is responsible for each picture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66e39d6c",
   "metadata": {},
   "source": [
    "We'll start by loading in our image data. We have 2 classes in our training data, Alex's photos and Kelly's photos. Hunter's photos are mixed into the testing data, to see if our model is able to distinguish a \"Neither\" category as well as Alex and Kelly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4bdaffb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e93b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# --- Load image paths ---\n",
    "def load_image_paths(base_dir):\n",
    "    data = []\n",
    "    for label in ['Alex', 'Kelly']:\n",
    "        path = os.path.join(base_dir, label)\n",
    "        if not os.path.exists(path):\n",
    "            print(f\"âš ï¸ Folder not found: {path}\")\n",
    "            continue\n",
    "        for ext in ('*.png', '*.jpg', '*.jpeg'):\n",
    "            for img_file in glob.glob(os.path.join(path, ext)):\n",
    "                data.append({'filepath': img_file, 'label': label})\n",
    "    df = pd.DataFrame(data)\n",
    "    print(f\"ðŸ“„ Loaded {len(df)} images.\")\n",
    "    return df\n",
    "\n",
    "# --- Prepare dataframe ---\n",
    "base_dir = '/Users/anhuynh/Downloads/Alex_Kelly_Pics'\n",
    "df = load_image_paths(base_dir)\n",
    "\n",
    "# Encode labels for stratification\n",
    "df['label_idx'] = df['label'].astype('category').cat.codes  # Alex=0, Kelly=1\n",
    "\n",
    "# --- Data generator ---\n",
    "datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b6212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 485 images total.\n",
      "                                            filepath label\n",
      "0  /Users/anhuynh/Downloads/Alex_Kelly_Pics/Alex/...  Alex\n",
      "1  /Users/anhuynh/Downloads/Alex_Kelly_Pics/Alex/...  Alex\n",
      "2  /Users/anhuynh/Downloads/Alex_Kelly_Pics/Alex/...  Alex\n",
      "3  /Users/anhuynh/Downloads/Alex_Kelly_Pics/Alex/...  Alex\n",
      "4  /Users/anhuynh/Downloads/Alex_Kelly_Pics/Alex/...  Alex\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b7c106",
   "metadata": {},
   "source": [
    "Let's start building our CNN model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2458720d",
   "metadata": {},
   "source": [
    "We will now train our CNN model on all of Kelly and Alex's pictures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd5cbf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“„ Loaded 485 images.\n",
      "\n",
      "ðŸ“‚ Fold 1\n",
      "Found 388 validated image filenames belonging to 2 classes.\n",
      "Found 97 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.5246 - loss: 1.5100 - val_accuracy: 0.5464 - val_loss: 0.6899\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 971ms/step - accuracy: 0.5581 - loss: 0.6860 - val_accuracy: 0.5670 - val_loss: 0.6683\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 981ms/step - accuracy: 0.5784 - loss: 0.6721 - val_accuracy: 0.5773 - val_loss: 0.6694\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 971ms/step - accuracy: 0.6063 - loss: 0.6706 - val_accuracy: 0.6907 - val_loss: 0.6387\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.5562 - loss: 0.6893 - val_accuracy: 0.5567 - val_loss: 0.6525\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 971ms/step - accuracy: 0.6346 - loss: 0.6324 - val_accuracy: 0.7010 - val_loss: 0.5877\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 981ms/step - accuracy: 0.6760 - loss: 0.5940 - val_accuracy: 0.7423 - val_loss: 0.5878\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 975ms/step - accuracy: 0.7074 - loss: 0.5717 - val_accuracy: 0.7526 - val_loss: 0.5880\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 984ms/step - accuracy: 0.7594 - loss: 0.4967 - val_accuracy: 0.7629 - val_loss: 0.5698\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.8108 - loss: 0.4309 - val_accuracy: 0.6701 - val_loss: 0.7071\n",
      "âœ… Fold 1 Accuracy: 0.7629\n",
      "\n",
      "ðŸ“‚ Fold 2\n",
      "Found 388 validated image filenames belonging to 2 classes.\n",
      "Found 97 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5207 - loss: 0.8405 - val_accuracy: 0.4742 - val_loss: 0.6911\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 975ms/step - accuracy: 0.5013 - loss: 0.6873 - val_accuracy: 0.5464 - val_loss: 0.6865\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 991ms/step - accuracy: 0.6027 - loss: 0.6468 - val_accuracy: 0.6598 - val_loss: 0.6848\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 987ms/step - accuracy: 0.7023 - loss: 0.6192 - val_accuracy: 0.6082 - val_loss: 0.6858\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 988ms/step - accuracy: 0.6869 - loss: 0.5897 - val_accuracy: 0.7010 - val_loss: 0.6380\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 972ms/step - accuracy: 0.7966 - loss: 0.5089 - val_accuracy: 0.6598 - val_loss: 0.6502\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.7879 - loss: 0.4436 - val_accuracy: 0.6907 - val_loss: 0.6497\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.8136 - loss: 0.3930 - val_accuracy: 0.6598 - val_loss: 0.7184\n",
      "âœ… Fold 2 Accuracy: 0.7010\n",
      "\n",
      "ðŸ“‚ Fold 3\n",
      "Found 388 validated image filenames belonging to 2 classes.\n",
      "Found 97 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.4879 - loss: 1.4176 - val_accuracy: 0.5464 - val_loss: 0.6916\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.5213 - loss: 0.6912 - val_accuracy: 0.5670 - val_loss: 0.6869\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.6264 - loss: 0.6829 - val_accuracy: 0.5361 - val_loss: 0.6786\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 992ms/step - accuracy: 0.5304 - loss: 0.6776 - val_accuracy: 0.6598 - val_loss: 0.6520\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 981ms/step - accuracy: 0.6461 - loss: 0.6388 - val_accuracy: 0.6186 - val_loss: 0.6881\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 982ms/step - accuracy: 0.6498 - loss: 0.6130 - val_accuracy: 0.6186 - val_loss: 0.7224\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 980ms/step - accuracy: 0.6914 - loss: 0.6168 - val_accuracy: 0.7113 - val_loss: 0.6170\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 975ms/step - accuracy: 0.7233 - loss: 0.5669 - val_accuracy: 0.6289 - val_loss: 0.6689\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 990ms/step - accuracy: 0.7185 - loss: 0.5512 - val_accuracy: 0.6804 - val_loss: 0.6130\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 996ms/step - accuracy: 0.7296 - loss: 0.5337 - val_accuracy: 0.5876 - val_loss: 0.7365\n",
      "âœ… Fold 3 Accuracy: 0.6804\n",
      "\n",
      "ðŸ“‚ Fold 4\n",
      "Found 388 validated image filenames belonging to 2 classes.\n",
      "Found 97 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5225 - loss: 1.3664 - val_accuracy: 0.5876 - val_loss: 0.6922\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.4847 - loss: 0.6931 - val_accuracy: 0.4845 - val_loss: 0.6970\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m160s\u001b[0m 13s/step - accuracy: 0.5573 - loss: 0.6768 - val_accuracy: 0.5567 - val_loss: 0.7231\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 1s/step - accuracy: 0.5649 - loss: 0.6887 - val_accuracy: 0.6186 - val_loss: 0.6460\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 984ms/step - accuracy: 0.7295 - loss: 0.5874 - val_accuracy: 0.6186 - val_loss: 0.6927\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 991ms/step - accuracy: 0.7228 - loss: 0.5708 - val_accuracy: 0.5979 - val_loss: 0.6655\n",
      "Epoch 7/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 971ms/step - accuracy: 0.6612 - loss: 0.6112 - val_accuracy: 0.6289 - val_loss: 0.6347\n",
      "Epoch 8/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 1s/step - accuracy: 0.7821 - loss: 0.5223 - val_accuracy: 0.6495 - val_loss: 0.6298\n",
      "Epoch 9/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 968ms/step - accuracy: 0.7638 - loss: 0.4930 - val_accuracy: 0.6392 - val_loss: 0.6797\n",
      "Epoch 10/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 963ms/step - accuracy: 0.8172 - loss: 0.4292 - val_accuracy: 0.7216 - val_loss: 0.5865\n",
      "âœ… Fold 4 Accuracy: 0.7216\n",
      "\n",
      "ðŸ“‚ Fold 5\n",
      "Found 388 validated image filenames belonging to 2 classes.\n",
      "Found 97 validated image filenames belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n",
      "/opt/anaconda3/lib/python3.12/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 1s/step - accuracy: 0.4919 - loss: 1.1474 - val_accuracy: 0.5258 - val_loss: 0.7055\n",
      "Epoch 2/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 979ms/step - accuracy: 0.5939 - loss: 0.6771 - val_accuracy: 0.5464 - val_loss: 0.6780\n",
      "Epoch 3/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 963ms/step - accuracy: 0.5756 - loss: 0.6624 - val_accuracy: 0.6598 - val_loss: 0.6616\n",
      "Epoch 4/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 984ms/step - accuracy: 0.7006 - loss: 0.6046 - val_accuracy: 0.5876 - val_loss: 0.7025\n",
      "Epoch 5/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 959ms/step - accuracy: 0.6867 - loss: 0.6391 - val_accuracy: 0.5464 - val_loss: 0.7136\n",
      "Epoch 6/10\n",
      "\u001b[1m13/13\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 976ms/step - accuracy: 0.7205 - loss: 0.5281 - val_accuracy: 0.6186 - val_loss: 0.7559\n",
      "âœ… Fold 5 Accuracy: 0.6598\n",
      "\n",
      "ðŸ“Š Average CV Accuracy: 0.7052 Â± 0.0355\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# --- K-Fold Cross Validation ---\n",
    "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "accuracies = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(kf.split(df['filepath'], df['label_idx'])):\n",
    "    print(f\"\\nðŸ“‚ Fold {fold+1}\")\n",
    "\n",
    "    train_df = df.iloc[train_idx]\n",
    "    val_df = df.iloc[val_idx]\n",
    "\n",
    "    train_gen = datagen.flow_from_dataframe(\n",
    "        train_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=True,\n",
    "        seed=42\n",
    "    )\n",
    "\n",
    "    val_gen = datagen.flow_from_dataframe(\n",
    "        val_df,\n",
    "        x_col='filepath',\n",
    "        y_col='label',\n",
    "        target_size=(224, 224),\n",
    "        batch_size=32,\n",
    "        class_mode='binary',\n",
    "        shuffle=False\n",
    "    )\n",
    "\n",
    "    # --- CNN Model builder ---\n",
    "    def create_model():\n",
    "        model = models.Sequential([\n",
    "            layers.Conv2D(32, (3, 3), activation='relu', input_shape=(224, 224, 3)),\n",
    "            layers.MaxPooling2D(2, 2),\n",
    "            layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D(2, 2),\n",
    "            layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "            layers.MaxPooling2D(2, 2),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(128, activation='relu'),\n",
    "            layers.Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    model = create_model()\n",
    "\n",
    "    # --- Early stopping ---\n",
    "    early_stop = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "    # --- Train model ---\n",
    "    history = model.fit(\n",
    "        train_gen,\n",
    "        validation_data=val_gen,\n",
    "        epochs=10,\n",
    "        callbacks=[early_stop],\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # --- Evaluate model ---\n",
    "    loss, acc = model.evaluate(val_gen, verbose=0)\n",
    "    print(f\"âœ… Fold {fold+1} Accuracy: {acc:.4f}\")\n",
    "    accuracies.append(acc)\n",
    "\n",
    "# --- Cross-validation results summary ---\n",
    "print(f\"\\nðŸ“Š Average CV Accuracy: {np.mean(accuracies):.4f} Â± {np.std(accuracies):.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd053a06",
   "metadata": {},
   "source": [
    "We cross validated on our training data to check the metrics, and we have a pretty decent average accuracy of 0.7052!\n",
    "Let's now find which fold did the best and then use it to predict on the test data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "207ed055",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "\n",
    "# Before the loop\n",
    "temp_dir = tempfile.gettempdir()\n",
    "model_paths = []\n",
    "\n",
    "# Inside the loop, after training\n",
    "model_path = os.path.join(temp_dir, f\"best_model_fold_{fold+1}.h5\")\n",
    "model.save(model_path)\n",
    "model_paths.append(model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d0826173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ† Best fold: 1 with accuracy 0.7629\n",
      "ðŸ“ Loading best model from: /var/folders/v9/hcdjkhvd5nq6llrn61tfl3qr0000gn/T/best_model_fold_5.h5\n"
     ]
    }
   ],
   "source": [
    "best_fold = np.argmax(accuracies)\n",
    "best_model_path = model_paths[best_fold]\n",
    "\n",
    "print(f\"\\nðŸ† Best fold: {best_fold+1} with accuracy {accuracies[best_fold]:.4f}\")\n",
    "print(f\"ðŸ“ Loading best model from: {best_model_path}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea7fdae",
   "metadata": {},
   "source": [
    "As we can see, Fold 1 presented us with the best accuracy! - this is the model we will use to predict our test data witt. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a0c0559f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20 validated image filenames.\n",
      "\u001b[1m1/1\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "              filename prediction\n",
      "0   TestSetImage01.png      Kelly\n",
      "1   TestSetImage15.png       Alex\n",
      "2   TestSetImage14.png       Alex\n",
      "3   TestSetImage16.png      Kelly\n",
      "4   TestSetImage02.png       Alex\n",
      "5   TestSetImage03.png      Kelly\n",
      "6   TestSetImage17.png      Kelly\n",
      "7   TestSetImage13.png      Kelly\n",
      "8   TestSetImage07.png      Kelly\n",
      "9   TestSetImage06.png      Kelly\n",
      "10  TestSetImage12.png      Kelly\n",
      "11  TestSetImage04.png      Kelly\n",
      "12  TestSetImage10.png      Kelly\n",
      "13  TestSetImage11.png       Alex\n",
      "14  TestSetImage05.png       Alex\n",
      "15  TestSetImage08.png      Kelly\n",
      "16  TestSetImage20.png      Kelly\n",
      "17  TestSetImage09.png      Kelly\n",
      "18  TestSetImage19.png      Kelly\n",
      "19  TestSetImage18.png      Kelly\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Load best model\n",
    "model = load_model(best_model_path)\n",
    "\n",
    "# Load test images\n",
    "test_dir = '/Users/anhuynh/Downloads/Alex_Kelly_Pics/TestSet'  # Folder with test images\n",
    "test_files = [os.path.join(test_dir, fname) for fname in os.listdir(test_dir) if fname.endswith(('.png', '.jpg', '.jpeg'))]\n",
    "\n",
    "# Create DataFrame for test set\n",
    "test_df = pd.DataFrame({'filepath': test_files})\n",
    "\n",
    "# Create test generator\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_gen = test_datagen.flow_from_dataframe(\n",
    "    test_df,\n",
    "    x_col='filepath',\n",
    "    y_col=None,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=32,\n",
    "    class_mode=None,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Predict\n",
    "preds = model.predict(test_gen)\n",
    "predicted_labels = (preds > 0.5).astype(int).flatten()\n",
    "label_map = {0: 'Alex', 1: 'Kelly'}\n",
    "predicted_names = [label_map[p] for p in predicted_labels]\n",
    "\n",
    "# Display predictions\n",
    "results = pd.DataFrame({\n",
    "    'filename': test_df['filepath'].apply(os.path.basename),\n",
    "    'prediction': predicted_names\n",
    "})\n",
    "print(results)\n",
    "\n",
    "# Optional: Save to CSV\n",
    "# results.to_csv(\"test_predictions.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8f9b27",
   "metadata": {},
   "source": [
    "Using our best CNN model and fold, we went ahead and predicted on the Test data to get these results!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
